33138980
Elasticsearch date histogram aggregation on a duration of time
<p>The documents that I deal with in Elasticsearch have the concept of duration represented as start and end time, e.g.</p>&#xA;&#xA;<pre><code>{&#xA;  issueId: 1,&#xA;  issuePriority: 3,&#xA;  timeWindow: {&#xA;    start: "2015-10-14T17:00:00-07:00",&#xA;    end: "2015-10-14T18:00:00-07:00"&#xA;  }&#xA;},&#xA;{&#xA;  issueId: 2,&#xA;  issuePriority: 1,&#xA;  timeWindow: {&#xA;    start: "2015-10-14T16:50:00-07:00",&#xA;    end: "2015-10-14T17:50:00-07:00"&#xA;  }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>My goal is to produce a histogram where number of issues and their max priority are aggregated into 15 minute buckets. So for the example above <code>issue #1</code> will be bucketized into the <code>17:00</code>, <code>17:15</code>, <code>17:30</code>, and <code>17:45</code> buckets, no more, no less.</p>&#xA;&#xA;<p>I tried using the <code>date_histogram</code> aggregation, e.g:</p>&#xA;&#xA;<pre><code>aggs: {&#xA;  max_priority_over_time: {&#xA;    date_histogram: {&#xA;      field: "timeWindow.start",&#xA;      interval: "15minute",&#xA;    },&#xA;    aggs: {&#xA;      max_priority: ${top_hits_aggregation}&#xA;    }&#xA;  }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>but obviously it is only bucketizing <code>issue #1</code> into the <code>17:00</code> bucket. Even if I were to take <code>timeWindow.end</code> into account it would only be added to the <code>18:00</code> bucket. Does anyone know how I can accomplish this using the <code>date_histogram</code> or other Elasticsearch aggregations? Potentially generating a range of timestamps 15 minutes apart from <code>timeWindow.start</code> to <code>timeWindow.end</code> so that they can be bucketized correctly. Thanks.</p>&#xA;
<p>By definition a bucketing operation will put each object returned by your query into one bucket and one only, i.e., you can't have it put the same object in multiple buckets at the same time in one query.</p>&#xA;&#xA;<p>If I understand your problem correctly then you need to do a series of queries applying a <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-range-filter.html" rel="nofollow">range filter</a> to get the number of issues in each 15 minute interval. So for each interval defined by you, you would get the issues that are open within that interval:</p>&#xA;&#xA;<pre><code>{&#xA;    "query": {&#xA;        "filtered": { &#xA;            "filter": {&#xA;                "bool": {&#xA;                    "must": [&#xA;                        "range": {&#xA;                            "timeWindow.start" : {&#xA;                                "lte" : "2015-10-14T17:00:00-07:00"&#xA;                            }&#xA;                        },&#xA;                        "range": {&#xA;                            "timeWindow.end" : {&#xA;                                "gte" : "2015-10-14T17:15:00-07:00"&#xA;                            }&#xA;                        },&#xA;                    ]&#xA;                }&#xA;            }&#xA;        }&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>(you would need to add your <code>max_priority</code> aggregation to the query).</p>&#xA;&#xA;<p>The range queries will be cached by elasticsearch so this should be fairly efficient. Assuming your historic data does not change you would be able to cache the result of historic intervals in your application as well.</p>&#xA;
<p>You will need to use a script for this. Create a script that emits an array of dates. These dates should start from the start date and each should increment by 15 minutes ( Assuming 15 minutes is the interval ). Now place this script in the script option of date_histogram.&#xA;So essentially the script should do the following - </p>&#xA;&#xA;<pre><code>start=2015-10-14T17:00:00-07:00&#xA;end=2015-10-14T18:00:00-07:00"&#xA;Output of script = [ "2015-10-14T17:00:00-07:00" , "2015-10-14T17:15:00-07:00" , "2015-10-14T17:30:00-07:00" , "2015-10-14T17:45:00-07:00" ,  "2015-10-14T18:00:00-07:00" ] &#xA;</code></pre>&#xA;&#xA;<p>To lean more on scripting you can go through this <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-scripting.html" rel="nofollow">Elasticsearch documentations</a>. These blogs might also be useful - <a href="https://qbox.io/blog/introduction-to-elasticsearch-scripting" rel="nofollow">This</a> , <a href="https://qbox.io/blog/elasticsearch-scripting-aggregations" rel="nofollow">this</a> and <a href="https://qbox.io/blog/logging-and-scripted_fields-in-elasticsearch" rel="nofollow">this</a>. </p>&#xA;
<p>Ok, since the timestamps for my data are always truncated to the nearest 10 minutes, I figured I can use a <code>nested terms aggregation</code> instead:</p>&#xA;&#xA;<pre><code>aggs: {&#xA;  per_start_time: {&#xA;    terms: {&#xA;      field: "timeWindow.start"&#xA;    },&#xA;    aggs: {&#xA;      per_end_time: {&#xA;        terms: {&#xA;          field: "timeWindow.end"&#xA;        },&#xA;        aggs: {&#xA;          max_priority: ${top_hits_aggregation}&#xA;        }&#xA;      }&#xA;    }&#xA;  }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>this gives me a nested bucket per start_time per end_time, e.g:</p>&#xA;&#xA;<pre><code>{&#xA;  "key": 1444867800000,&#xA;  "key_as_string": "2015-10-15T00:10:00.000Z",&#xA;  "doc_count": 11,&#xA;  "per_end_time": {&#xA;    "doc_count_error_upper_bound": 0,&#xA;    "sum_other_doc_count": 0,&#xA;    "buckets": [&#xA;      {&#xA;        "key": 1444871400000,&#xA;        "key_as_string": "2015-10-15T01:10:00.000Z",&#xA;        "doc_count": 11,&#xA;        "max_priority": {&#xA;          "hits": {&#xA;            "total": 11,&#xA;            "max_score": 4,&#xA;          }&#xA;        }&#xA;      }&#xA;    ]&#xA;  }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>by trimming down the buckets in our backend (ruby on rails), I could get the following results:</p>&#xA;&#xA;<pre><code>[&#xA;  {&#xA;    "start_time": "2015-10-14 14:40:00 -0700",&#xA;    "end_time": "2015-10-14 15:40:00 -0700",&#xA;    "max_priority": 4,&#xA;    "count": 12&#xA;  }&#xA;],&#xA;[&#xA;  {&#xA;    "start_time": "2015-10-14 14:50:00 -0700",&#xA;    "end_time": "2015-10-14 15:50:00 -0700",&#xA;    "max_priority": 4,&#xA;    "count": 12&#xA;  }&#xA;],&#xA;...&#xA;</code></pre>&#xA;&#xA;<p>which can be map/reduced further into a date histogram with arbitrary time buckets, outside of elasticsearch of course. If <code>timeWindow.start</code>, <code>timeWindow.end</code> and the window duration are completely arbitrary in time, I guess it'd be equivalent of just fetching everything and doing the counting in backend (since it's almost generating one nested time bucket per document), fortunately the timestamps that I deal with are somewhat predictable so I can take this hybrid approach. </p>&#xA;