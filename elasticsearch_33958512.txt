33958512
How to match parts of a word in elasticsearch?
<p>How can I match parts of a word to the parent word ?. For example: I need to match "eese" or "heese" to the word "cheese". </p>&#xA;
<p>You can do it two ways:</p>&#xA;&#xA;<ol>&#xA;<li><p>If you need it happen only for some search then search box only you can pass </p>&#xA;&#xA;<p>*eese*   or *heese*</p></li>&#xA;</ol>&#xA;&#xA;<p>Just give * in beginning and end of your search word. If you need it for every search</p>&#xA;&#xA;<pre><code> string "*#{params[:query]}*"&#xA;</code></pre>&#xA;&#xA;<p>this will match with your parent word and give the result</p>&#xA;
<p>The best way to achieve this is using an <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-edgengram-tokenfilter.html" rel="nofollow"><code>edgeNGram</code> token filter</a> combined with two <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-reverse-tokenfilter.html" rel="nofollow"><code>reverse</code> token filters</a>. So, first you need to define a custom analyzer called <code>reverse_analyzer</code> in your index settings like below. Then you can see that I've declared a string field called <code>your_field</code> with a sub-field called <code>suffix</code> which has our custom analyzer defined.</p>&#xA;&#xA;<pre><code>PUT your_index&#xA;{&#xA;  "settings": {&#xA;    "analysis": {&#xA;      "analyzer": {&#xA;        "reverse_analyzer": {&#xA;          "tokenizer": "keyword",&#xA;          "filter" : ["lowercase", "reverse", "substring", "reverse"]&#xA;        }&#xA;      },&#xA;      "filter": {&#xA;        "substring": {&#xA;          "type": "edgeNGram",&#xA;          "min_gram": 1,&#xA;          "max_gram": 10&#xA;        }&#xA;      }&#xA;    }&#xA;  },&#xA;  "mappings": {&#xA;    "your_type": {&#xA;      "properties": {&#xA;        "your_field": {&#xA;          "type": "string",&#xA;          "fields": {&#xA;            "suffix": {&#xA;              "type": "string",&#xA;              "analyzer": "reverse_analyzer"&#xA;            }&#xA;          }&#xA;        }&#xA;      }&#xA;    }&#xA;  }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Then you can index a test document with "cheese" inside, like this:</p>&#xA;&#xA;<pre><code>PUT your_index/your_type/1&#xA;{"your_field": "cheese"}&#xA;</code></pre>&#xA;&#xA;<p>When this document is indexed, the <code>your_field.suffix</code> field will contain the following tokens:</p>&#xA;&#xA;<ul>&#xA;<li><code>e</code></li>&#xA;<li><code>se</code></li>&#xA;<li><code>ese</code></li>&#xA;<li><code>eese</code></li>&#xA;<li><code>heese</code></li>&#xA;<li><code>cheese</code></li>&#xA;</ul>&#xA;&#xA;<p>Under the hood what is happening when indexing <code>cheese</code> is the following:</p>&#xA;&#xA;<ol>&#xA;<li>The <code>keyword</code> tokenizer will tokenize a single token, => <code>cheese</code></li>&#xA;<li>The <code>lowercase</code> token filter will put the token in lowercase => <code>cheese</code></li>&#xA;<li>The <code>reverse</code> token filter will reverse the token => <code>eseehc</code></li>&#xA;<li>The <code>substring</code> token filter will produce different tokens of length 1 to 10 => <code>e</code>, <code>es</code>, <code>ese</code>, <code>esee</code>, <code>eseeh</code>, <code>eseehc</code> </li>&#xA;<li>Finally, the second <code>reverse</code> token filter will reverse again all tokens => <code>e</code>, <code>se</code>, <code>ese</code>, <code>eese</code>, <code>heese</code>, <code>cheese</code></li>&#xA;<li>Those are all the tokens that will be indexed   </li>&#xA;</ol>&#xA;&#xA;<p>So we can finally search for <code>eese</code> (or any suffix of <code>cheese</code>) in that sub-field and find our match</p>&#xA;&#xA;<pre><code>POST your_index/_search&#xA;{&#xA;   "query": {&#xA;      "match": {&#xA;         "your_field.suffix": "eese"&#xA;      }&#xA;   }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>=> Yields the document we've just indexed above.</p>&#xA;
<p>There are multiple ways to do this </p>&#xA;&#xA;<ol>&#xA;<li><p>The analyzer approach - Here you <a href="https://www.elastic.co/guide/en/elasticsearch/reference/1.4/analysis-ngram-tokenizer.html" rel="nofollow">Ngram tokenizer</a> to break sub tokens of all the words. Hence for the word "cheese" -> [ "chee" , "hees" , "eese" , "cheese" ] and all ind of substrings would be generated. With this index size will go high , but the search speed would be optimized</p></li>&#xA;<li><p>The <a href="https://www.elastic.co/guide/en/elasticsearch/reference/1.4/query-dsl-wildcard-query.html" rel="nofollow">wildcard query</a> approach - In this approach , a scan happens on the reverse index. This does not occupy additional index size , but it will take more time on the search.</p></li>&#xA;</ol>&#xA;