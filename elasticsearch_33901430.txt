33901430
Efficiently updating a large number of array-type fields
<p>I am looking for an efficient way to update large numbers of entries in my index. Let's say my ElasticSearch index contains documents with tags. Tags are expressed as arrays of strings. So one document might have tags <code>['foo', 'bar']</code> and some other document might have tags <code>['bar', 'baz']</code>.</p>&#xA;&#xA;<p>Typically I need to add a certain tag to a number of documents (I know their IDs) and remove this tag from all other documents. There are about half a million documents in the index and growing, and I need to update tens, maybe hundreds of thousands of documents.</p>&#xA;&#xA;<p>The operation doesn't need to be atomic. There are no problems with concurrent writing, I can be pretty sure there are no other write operations on that index while I'm updating.</p>&#xA;&#xA;<p>My goal is for this update to be done as quickly as possible.</p>&#xA;&#xA;<p>Let's imagine I need to set tag <code>'foo'</code> to documents 123, 456 and 555. </p>&#xA;&#xA;<p>Should I remove tag <code>'foo'</code> from all documents in the index, and then add it to 123, 456 and 555? Or should I first get the list of documents that need to have that tag removed, then remove tag only from those documents and add only to documents that need it?</p>&#xA;&#xA;<p>Are there any other ways of solving this problem?</p>&#xA;&#xA;<p>UPDATE:&#xA;So far I've discovered that the biggest bottleneck is actually updating the entries. Apparently, ES does updates by reindexing the whole document, and that takes so long, that in terms of performance everything else (choosing which documents to update) is not significant.</p>&#xA;