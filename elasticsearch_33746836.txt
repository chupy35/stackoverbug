33746836
Boost if result begin with the word
<p>I use Elasticsearch to search with autocompletion with an ngram filter. I need to boost a result if it starts with the search keyword.</p>&#xA;&#xA;<p>My query is simple :</p>&#xA;&#xA;<pre><code>"query": {&#xA;   "match": {&#xA;      "query": "re",&#xA;      "operator": "and"&#xA;   }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>And this is my results :</p>&#xA;&#xA;<ul>&#xA;<li><strong>Re</strong>staurants</li>&#xA;<li>Couture et <strong>re</strong>touches</li>&#xA;<li><strong>Re</strong>stauration rapide</li>&#xA;</ul>&#xA;&#xA;<p>But I want them like this :</p>&#xA;&#xA;<ul>&#xA;<li><strong>Re</strong>staurants</li>&#xA;<li><strong>Re</strong>stauration rapide</li>&#xA;<li>Couture et <strong>re</strong>touches</li>&#xA;</ul>&#xA;&#xA;<p>How can I boost a result starting with the keyword?</p>&#xA;&#xA;<p>In case it can helps, here is my mapping :</p>&#xA;&#xA;<pre><code>{&#xA;    "settings": {&#xA;        "analysis": {&#xA;            "analyzer": {&#xA;                "partialAnalyzer": {&#xA;                    "type": "custom",&#xA;                    "tokenizer": "ngram_tokenizer",&#xA;                    "filter": ["asciifolding", "lowercase"]&#xA;                },&#xA;                "searchAnalyzer": {&#xA;                    "type": "custom",&#xA;                    "tokenizer": "standard",&#xA;                    "filter": ["asciifolding", "lowercase"]&#xA;                }&#xA;            },&#xA;&#xA;            "tokenizer": {&#xA;                "ngram_tokenizer": {&#xA;                    "type": "edge_ngram",&#xA;                    "min_gram": "1",&#xA;                    "max_gram": "15",&#xA;                    "token_chars": [ "letter", "digit" ]&#xA;                }&#xA;            }&#xA;        }&#xA;    },&#xA;&#xA;    "mappings": {&#xA;        "place": {&#xA;            "properties": {&#xA;                "name": {&#xA;                    "type": "string",&#xA;                    "index_analyzer": "partialAnalyzer",&#xA;                    "search_analyzer": "searchAnalyzer",&#xA;                    "term_vector": "with_positions_offsets"&#xA;                }&#xA;            }&#xA;        }&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Regards,</p>&#xA;
<p>How about this idea, not 100% sure of it as it  depends on the data I think:</p>&#xA;&#xA;<ul>&#xA;<li>create a sub-field in your <code>name</code> field that should be analyzed with <code>keyword</code> analyzer (pretty much staying as is)</li>&#xA;<li>change the query to be a <code>bool</code> with <code>should</code>s</li>&#xA;<li>one <code>should</code> is the query you have now</li>&#xA;<li>the other <code>should</code> is a <code>match</code> with <code>phrase_prefix</code> on the sub-field.</li>&#xA;</ul>&#xA;&#xA;<p>The mapping:</p>&#xA;&#xA;<pre><code>{&#xA;  "settings": {&#xA;    "analysis": {&#xA;      "analyzer": {&#xA;        "partialAnalyzer": {&#xA;          "type": "custom",&#xA;          "tokenizer": "ngram_tokenizer",&#xA;          "filter": [&#xA;            "asciifolding",&#xA;            "lowercase"&#xA;          ]&#xA;        },&#xA;        "searchAnalyzer": {&#xA;          "type": "custom",&#xA;          "tokenizer": "standard",&#xA;          "filter": [&#xA;            "asciifolding",&#xA;            "lowercase"&#xA;          ]&#xA;        },&#xA;        "keyword_lowercase": {&#xA;          "type": "custom",&#xA;          "tokenizer": "keyword",&#xA;          "filter": [&#xA;            "asciifolding",&#xA;            "lowercase"&#xA;          ]&#xA;        }&#xA;      },&#xA;      "tokenizer": {&#xA;        "ngram_tokenizer": {&#xA;          "type": "edge_ngram",&#xA;          "min_gram": "1",&#xA;          "max_gram": "15",&#xA;          "token_chars": [&#xA;            "letter",&#xA;            "digit"&#xA;          ]&#xA;        }&#xA;      }&#xA;    }&#xA;  },&#xA;  "mappings": {&#xA;    "place": {&#xA;      "properties": {&#xA;        "name": {&#xA;          "type": "string",&#xA;          "index_analyzer": "partialAnalyzer",&#xA;          "search_analyzer": "searchAnalyzer",&#xA;          "term_vector": "with_positions_offsets",&#xA;          "fields": {&#xA;            "as_is": {&#xA;              "type": "string",&#xA;              "analyzer": "keyword_lowercase"&#xA;            }&#xA;          }&#xA;        }&#xA;      }&#xA;    }&#xA;  }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>The query:</p>&#xA;&#xA;<pre><code>{&#xA;  "query": {&#xA;    "bool": {&#xA;      "should": [&#xA;        {&#xA;          "match": {&#xA;            "name": {&#xA;              "query": "re",&#xA;              "operator": "and"&#xA;            }&#xA;          }&#xA;        },&#xA;        {&#xA;          "match": {&#xA;            "name.as_is": {&#xA;              "query": "re",&#xA;              "type": "phrase_prefix"&#xA;            }&#xA;          }&#xA;        }&#xA;      ]&#xA;    }&#xA;  }&#xA;}&#xA;</code></pre>&#xA;