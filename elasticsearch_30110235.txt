30110235
Getting oldest value per field
<p>I have a single elasticsearch index that contains a set of documents that have a due date which is a datetime field, an account id, other various fields and a UUID for its doc id.</p>&#xA;&#xA;<p>I would like to issue a query to elasticsearch that gives me the document with the oldest due date per account id. This is a query I would send to get the account ids that have the 10 oldest items in the index. This query does not allow me to page through the results and I am curious if anyone knows of a way that I would write this query (possibly the top hits aggregation) that would allow me to page through these results?</p>&#xA;&#xA;<pre><code>{&#xA;  'query': {&#xA;    'match_all': {&#xA;&#xA;    }&#xA;  },&#xA;  'aggs': {&#xA;    'account_id': {&#xA;      'terms': {&#xA;        'field': 'account_id',&#xA;        'size': 10,&#xA;        'order' : { "min_due_date" : "asc" }&#xA;      },&#xA;      'aggs': {&#xA;        'min_due_date': {&#xA;          'min': {&#xA;            'field': 'due_date'&#xA;          }&#xA;        }&#xA;      }&#xA;    }&#xA;  }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Today we store the oldest due date per account in a separate index that we manually have to keep updated. It would be great if I could get elastic search to accomplish this with a query in real time.</p>&#xA;&#xA;<p>Thanks.</p>&#xA;
<p>You cannot page through aggregations. The ability to page hits requires those hits to be recalculated on demand, and the same goes for buckets.</p>&#xA;&#xA;<p>So, if you need the 11th to 20th hits, then you need to determine the top 20, then throw away the top 10. For the 21st to 30th hits, you need to determine the top 30, then throw away the top 20. This continues perpetually until you stop paging.</p>&#xA;&#xA;<p>For <em>normal</em> searches, which do not use aggregations, you can side-step this issue by using scan and scroll, but you lose the ability to sort. It's certainly a trade off, but it's worth it to save your cluster's health from the <a href="http://www.elastic.co/guide/en/elasticsearch/guide/current/pagination.html" rel="nofollow">cost of deep paging</a>.</p>&#xA;&#xA;<p>In terms of aggregations, the cost of paging would be <em>very</em> high. Aggregating is an expensive problem (at scale), so allowing the paging of it would be problematic. Therefore the way to approach that problem is to request the appropriate size upfront -- accept the burden once rather than the burden multiple times. The only real change will be the background work done to maintain the related shard size; the processing still takes place regardless. So the real cost is: added network overhead (sending across each shard's top N to figure out the actual top N) plus a little extra work processing the added results.</p>&#xA;