33257971
Elastic Search Custom char_filter analyzer not working as (I) expected
<p>I have added the following custom analyzer to my elastic search index.  </p>&#xA;&#xA;<pre><code>{&#xA;"index" : {&#xA;    "analysis" : {&#xA;        "char_filter" : {&#xA;            "acc_mapping" : {&#xA;                "type" : "mapping",&#xA;                "mappings" : ["/=&gt;"]&#xA;            }&#xA;        },&#xA;        "analyzer" : {&#xA;            "accno_char_filter" : {&#xA;                "tokenizer" : "standard",&#xA;                "char_filter" : ["acc_mapping"]&#xA;            }&#xA;        }&#xA;    }&#xA;}&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Essentially we have a lot of data feeds and legacy data and the account number can vary in format.  The current (and majority of data) format is along the lines of acc/vb123/123 and this was causing problems in that it was being tokenised into acc, vb123 and 123.  I have a hack solution (in my java app) where if only the account number is searched on I 'hard code' an exact match search in i.e. acc/vb123/123 becomes \"acc/vb123/123\".  This is not something I'm proud of but it does the job in most cases (people either tend to search for account number OR text so my hack hasn't become too obvious yet...)  I am not an expert in elastic search but I am intermittently trying to put a proper solution in place.   </p>&#xA;&#xA;<p>The mapping above has cut down the results from thousands to hundreds but I was expecting it to cut down to 1 in most cases.  On investigation what seems to be happening is searching for acc/vb123/123 is no longer picking up other accounts in this format (starting with acc or ending with 123 for example) but it is still picking up other fomats with a - in so for example searching on acc/vb123/123 will also return oldref-123.  </p>&#xA;&#xA;<p>Using postman my crude test search is </p>&#xA;&#xA;<pre><code>{&#xA;  "query" : {&#xA;  "filtered" : {&#xA;     "query" : {&#xA;         "query_string" : {&#xA;            "query" : "acc/vb123/123",&#xA;            "fields" : [ "customer.accno" ],&#xA;            "analyzer": "accno_char_filter"&#xA;                          }&#xA;               }&#xA;               }&#xA;           }&#xA;  }&#xA;</code></pre>&#xA;&#xA;<p>the mapping file used to build the index contains</p>&#xA;&#xA;<pre><code>"accno": {&#xA;        "type": "string",&#xA;        "analyzer": "accno_char_filter",&#xA;        "store": true&#xA;    },&#xA;</code></pre>&#xA;&#xA;<p>I thought this would mean as far as the index and search were concerned the field stored and searched for would be 1 block of text "accvb123123" and thus would not be tokenised or analyzed into any sub components.  </p>&#xA;&#xA;<p>I appear to be wrong as it is picking up accounts with a -, like oldref-123 as I explained.  I'm guessing this may be to do with using "tokenizer" : "standard" but I wondered if anyone could explain why this would be happening  before I start ripping it apart (or adding a ["-=>"] mapping to see if that helps without breaking anything!)</p>&#xA;&#xA;<p>Thanks in advance.</p>&#xA;&#xA;<p>Edit:</p>&#xA;&#xA;<p>The actual application offers the user one text entry box and uses the content to search 3 fields.  One field is account number, 1 field is name and one field is description.  Description can be a long section very vague text.  It can contain account numbers of related accounts (although usually doesn't).  In general the search works perfectly (or close to) out of the box.  The only issue is that the way it is designed someone may enter an account number in the text box, expecting to see the exact match from the account number field (and any cases where it is in the description field if it is) or they may enter some general text "credit problems Northampton" where they would expect to see results of credit AND problems AND Northampton.  The issue is that the way it is designed if they enter an account number they thus get thousands of results with an out of the box set up as once tokenised the account number search say acc/ab12/123 searches for acc, ab12 and 123.  I've been slowly and gradually looking for a way to stop acc/ab12/123 being tokenised in any of the 3 fields and so that one could search for acc/ab12/123 and only get 1 result (account number = acc/ab12/123) without stopping the possibility of a proper text search.</p>&#xA;&#xA;<p>This is something I have worked on gradually as time allows as there are plenty of work-arounds (even disregarding the hack I have put in place) - The user can place quotes around the search text and search for ["acc/ab12/123"]  or even go to "options" and select to only search the account number field.  Also the most relevant matches appear first so it isn't like thousands of results makes the application unusable.  From a dev/support perspective this is a non problem (!) but the business get upset when they see thousands of results when searching an account number using the default search options and and I would like to learn elasticsearch customisation better and so I am gradually trying to customise it according to their requirement.</p>&#xA;