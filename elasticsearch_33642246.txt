33642246
How to match multiple words as token prefixes
<p>I'd like to take a query like "jan do" and have it match values like "jane doe", "don janek" -- and of course: "jan do", "do jan".</p>&#xA;&#xA;<p>So the rules I can think of at the moment are:</p>&#xA;&#xA;<ol>&#xA;<li>tokenize the query based on non-alphanumeric values (e.g. whitespace, symbols, punctuation)</li>&#xA;<li>each query token acts as a prefix for matching tokens in the data store</li>&#xA;<li>the order the tokens appear does not matter. It would be nice to prefer "jan do" to "do jan"</li>&#xA;</ol>&#xA;&#xA;<p>So far, I have this mapping</p>&#xA;&#xA;<pre><code>PUT /test&#xA;{&#xA;  "settings": {&#xA;    "analysis": {&#xA;      "analyzer": {&#xA;        "my_keyword": {&#xA;          "type": "custom",&#xA;          "tokenizer": "keyword",&#xA;          "filter": [&#xA;            "asciifolding",&#xA;            "lowercase"&#xA;          ]&#xA;        }&#xA;      }&#xA;    }&#xA;  },&#xA;  "mappings": {&#xA;    "question": {&#xA;      "properties": {&#xA;        "title": {&#xA;          "type": "string"&#xA;        },&#xA;        "answer": {&#xA;          "type": "object",&#xA;          "properties": {&#xA;            "text": {&#xA;              "type": "string",&#xA;              "analyzer": "my_keyword",&#xA;              "fields": {&#xA;                "stemmed": {&#xA;                  "type": "string",&#xA;                  "analyzer": "standard"&#xA;                }&#xA;              }&#xA;            }&#xA;          }&#xA;        }&#xA;      }&#xA;    }&#xA;  }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>I've been searching things as phrases:</p>&#xA;&#xA;<pre><code>POST /test/_search&#xA;{&#xA;  "query": {&#xA;    "dis_max": {&#xA;      "tie_breaker": 0.7,&#xA;      "boost": 1.2,&#xA;      "queries": [&#xA;        {&#xA;          "match": {&#xA;            "answer.text": {&#xA;              "query": "jan do",&#xA;              "type": "phrase_prefix"&#xA;            }&#xA;          }&#xA;        },&#xA;        {&#xA;          "match": {&#xA;            "answer.text.stemmed": {&#xA;              "query": "jan do",&#xA;              "operator": "and"&#xA;            }&#xA;          }&#xA;        }&#xA;      ]&#xA;    }&#xA;  }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>And that works okay when things actually start that phrase, but now I want to tokenize the query and treat each token like a prefix.</p>&#xA;&#xA;<p>Is there a way I can do this (probably at query time)?</p>&#xA;&#xA;<p>My other option is to just construct a query like this:</p>&#xA;&#xA;<pre><code>POST test/_search&#xA;{&#xA;  "query": {&#xA;    "bool": {&#xA;      "should": [&#xA;        {&#xA;          "prefix": {&#xA;            "answer.text.stemmed": "jan"&#xA;          }&#xA;        },&#xA;        {&#xA;          "prefix": {&#xA;            "answer.text.stemmed": "do"&#xA;          }&#xA;        }&#xA;      ]&#xA;    }&#xA;  }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>This seems to work, but it doesn't preserve the order of the words. Also, I feel like that's cheating and possibly not the most performant option. What if there were 10 prefixes? 100? I'd like to know whether anyone feels otherwise.</p>&#xA;
<p>As the comment above suggests, you should take a look at <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-ngram-tokenizer.html" rel="nofollow">ngrams</a> in Elasticsearch, and in particular <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-edgengram-tokenizer.html" rel="nofollow">edge ngrams</a>.</p>&#xA;&#xA;<p>I wrote up an introduction to using ngrams in <a href="https://qbox.io/blog/an-introduction-to-ngrams-in-elasticsearch" rel="nofollow">this blog post</a> for <a href="https://qbox.io" rel="nofollow">Qbox</a>, but here is a quick example you can play with.</p>&#xA;&#xA;<p>Here is an index definition that applies an <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-edgengram-tokenfilter.html" rel="nofollow">edge ngram token filter</a> as well as several other filters to a custom analyzer (using the <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-standard-tokenizer.html?q=standard%20tokenizer#analysis-standard-tokenizer" rel="nofollow">standard tokenizer</a>).</p>&#xA;&#xA;<p>There have been some changes in the way <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/breaking_20_mapping_changes.html#_analyzer_mappings" rel="nofollow">analyzers are applied</a> in ES 2.0. But notice that I am using the <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-standard-analyzer.html" rel="nofollow">standard analyzer</a> for the <code>"search_analyzer"</code>. This is because I don't want the search text to be tokenized into ngrams, I want it to be matched directly to indexed tokens. I'll refer you to the blog post for a description of the details.</p>&#xA;&#xA;<p>Anyway, here is the mapping:</p>&#xA;&#xA;<pre><code>PUT /test_index&#xA;{&#xA;   "settings": {&#xA;      "analysis": {&#xA;         "analyzer": {&#xA;            "autocomplete": {&#xA;               "type": "custom",&#xA;               "tokenizer": "standard",&#xA;               "filter": [&#xA;                  "standard",&#xA;                  "stop",&#xA;                  "kstem",&#xA;                  "edgengram_filter"&#xA;               ]&#xA;            }&#xA;         },&#xA;         "filter": {&#xA;            "edgengram_filter": {&#xA;               "type": "edgeNGram",&#xA;               "min_gram": 2,&#xA;               "max_gram": 15&#xA;            }&#xA;         }&#xA;      }&#xA;   },&#xA;   "mappings": {&#xA;      "doc": {&#xA;         "properties": {&#xA;            "name": {&#xA;               "type": "string",&#xA;               "analyzer": "autocomplete",&#xA;               "search_analyzer": "standard"&#xA;            },&#xA;            "price":{&#xA;                "type": "integer"&#xA;            }&#xA;         }&#xA;      }&#xA;   }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Then I index a few simple documents:</p>&#xA;&#xA;<pre><code>POST /test_index/doc/_bulk&#xA;{"index":{"_id":1}}&#xA;{"name": "very cool shoes","price": 26}&#xA;{"index":{"_id":2}}&#xA;{"name": "great shampoo","price": 15}&#xA;{"index":{"_id":3}}&#xA;{"name": "shirt","price": 25}&#xA;</code></pre>&#xA;&#xA;<p>And now the following query will get me the expected autocomplete results:</p>&#xA;&#xA;<pre><code>POST /test_index/_search&#xA;{&#xA;   "query": {&#xA;      "match": {&#xA;         "name": {&#xA;            "query": "ver sh",&#xA;            "operator": "and"&#xA;         }&#xA;      }&#xA;   }&#xA;}&#xA;...&#xA;{&#xA;   "took": 4,&#xA;   "timed_out": false,&#xA;   "_shards": {&#xA;      "total": 5,&#xA;      "successful": 5,&#xA;      "failed": 0&#xA;   },&#xA;   "hits": {&#xA;      "total": 1,&#xA;      "max_score": 0.2169777,&#xA;      "hits": [&#xA;         {&#xA;            "_index": "test_index",&#xA;            "_type": "doc",&#xA;            "_id": "1",&#xA;            "_score": 0.2169777,&#xA;            "_source": {&#xA;               "name": "very cool shoes",&#xA;               "price": 26&#xA;            }&#xA;         }&#xA;      ]&#xA;   }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Here is all the code I used in the example:</p>&#xA;&#xA;<p><a href="http://sense.qbox.io/gist/c2ba05900d0749fa3b1ba516c66431ae1a9d5e61" rel="nofollow">http://sense.qbox.io/gist/c2ba05900d0749fa3b1ba516c66431ae1a9d5e61</a></p>&#xA;