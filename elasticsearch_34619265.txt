34619265
ElasticSearch Unassigned shards with two nodes( different machines), 1 master both new instances
<p>I started up two clean elasticsearch instances (nodes), no data, two different machines ( one windows, one osx).  They successfully discover each other.  One is node.master: false. Both are node.data: true.  I started Kibana ( creates te .kibana index ) and I created a test index (test), number_of_replicas=1 and the status of each index and the cluster is yellow which I believe is because of unassigned shards. I am at a loss how to get the unassigned shards to resolve.</p>&#xA;&#xA;<p>In trying to force the replication of the shard I get the following error:</p>&#xA;&#xA;<pre><code>shard cannot be allocated on same node [tNUHIE6cTHO6h37P_s3m7w] it already exists on&#xA;</code></pre>&#xA;&#xA;<p>Some details: </p>&#xA;&#xA;<p>_cat/nodes?v:</p>&#xA;&#xA;<pre><code> host         ip       heap.percent ram.percent  load node.role master name              &#xA;192.168.1.99 192.168.1.99     2          81  1.95 d         *      node1     &#xA;192.168.1.2  192.168.1.2     13          46 -1.00 d         -      node2 &#xA;</code></pre>&#xA;&#xA;<p>Node 1: _cluster/health</p>&#xA;&#xA;<pre><code>{&#xA; "cluster_name": "elasticsearch",&#xA; "status": "yellow",&#xA; "timed_out": false,&#xA; "number_of_nodes": 2,&#xA; "number_of_data_nodes": 2,&#xA; "active_primary_shards": 6,&#xA; "active_shards": 9,&#xA; "relocating_shards": 0,&#xA; "initializing_shards": 0,&#xA; "unassigned_shards": 3,&#xA; "delayed_unassigned_shards": 0,&#xA; "number_of_pending_tasks": 0,&#xA; "number_of_in_flight_fetch": 0,&#xA; "task_max_waiting_in_queue_millis": 0,&#xA; "active_shards_percent_as_number": 75&#xA;</code></pre>&#xA;&#xA;<p>}</p>&#xA;&#xA;<p>There are no errors in the logs but if I run:</p>&#xA;&#xA;<p>_cluster/reroute?pretty</p>&#xA;&#xA;<pre><code>{ "commands" : [ { "allocate" : { "index" : "test", "shard" : 1, "node" : "node2" } } ] &#xA;}&#xA;</code></pre>&#xA;&#xA;<p>I get the following response:</p>&#xA;&#xA;<pre><code>{ "error": {&#xA;  "root_cause": [&#xA;     {&#xA;        "type": "illegal_argument_exception",&#xA;        "reason": "[allocate] allocation of [test][1] on node { node2}{tNUHIE6cTHO6h37P_s3m7w}{192.168.1.2}{192.168.1.2:9300}{master=false} is not allowed, &#xA;         reason: [YES(target node version [2.1.1] is same or newer than source node version [2.1.1])] &#xA;         [YES(enough disk for shard on node, free: [111.6gb])]&#xA;         [YES(shard not primary or relocation disabled)]&#xA;         [YES(primary is already active)][YES(node passes include/exclude/require filters)]&#xA;         [YES(allocation disabling is ignored)]&#xA;         [NO(shard cannot be allocated on same node [tNUHIE6cTHO6h37P_s3m7w] it already exists on)]&#xA;         [YES(total shard limit disabled: [index: -1, cluster: -1] &lt;= 0)][YES(below shard recovery limit of [2])][YES(no allocation awareness enabled)][YES(allocation disabling is ignored)]"&#xA;     }&#xA;     ],&#xA;  ...&#xA;  "status": 400&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>_cat/shards?v</p>&#xA;&#xA;<pre><code>  index   shard prirep state      docs store ip           node          &#xA; test      3     p      STARTED       0  130b 192.168.1.2 node2 &#xA; test      3     r      UNASSIGNED                                          &#xA; test      4     r      STARTED       0  130b 192.168.1.2  node2&#xA; test      4     p      STARTED       0  130b 192.168.1.99 node1   &#xA; test      1     p      STARTED       0  130b 192.168.1.2 node2&#xA; test      1     r      UNASSIGNED                                       &#xA; test      2     r      STARTED       0  130b 192.168.1.2  node2&#xA; test      2     p      STARTED       0  130b 192.168.1.99 node1&#xA; test      0     r      STARTED       0  130b 192.168.1.2 node2&#xA; test      0     p      STARTED       0  130b 192.168.1.99 node1     &#xA; .kibana 0    p      STARTED       1 3.1kb 192.168.1.2  node2 &#xA; .kibana 0    r      UNASSIGNED        &#xA;</code></pre>&#xA;&#xA;<p>Any help for a newbie would be apprecitated in resolving this.</p>&#xA;
<p>You can only reroute replica shards safely. <code>GET _cat/shards?v</code> clearly shows that shard (primary) of id 1 of <code>test</code> index is already allocated on <code>node2</code>. You cannot allocate a shard on the same node it is already allocated on. That is exactly what the output of <code>_cluster/reroute</code> command is telling you. Instead of allocating on <code>node2</code>, allocate it on <code>node1</code>. Try the command below:</p>&#xA;&#xA;<pre><code>POST _cluster/reroute?explain&#xA;{&#xA;   "commands": [&#xA;      {&#xA;         "allocate": {&#xA;            "index": "test",&#xA;            "shard": 1,&#xA;            "node": "node1"&#xA;         }&#xA;      },&#xA;      {&#xA;         "allocate": {&#xA;            "index": "test",&#xA;            "shard": 2,&#xA;            "node": "node1"&#xA;         }&#xA;      }&#xA;   ]&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>This will try to allocate both the unassigned replica shards. Also note the <code>explain</code> option. The response of the command will give a verbose explanation as to why the commands succeeded or failed and that comes in very handy while debugging if the commands do fail.</p>&#xA;