31953175
ngram not working on symbol elasticsearch
<p>These are my settings:</p>&#xA;&#xA;<pre><code>"nGram_filter": {&#xA;      "type": "nGram",&#xA;      "min_gram": 2,&#xA;      "max_gram": 20,&#xA;      "token_chars": [&#xA;        "letter",&#xA;        "digit",&#xA;        "punctuation",&#xA;        "symbol"&#xA;      ]&#xA;    }&#xA;  },&#xA;  "analyzer": {&#xA;    "nGram_analyzer": {&#xA;      "type": "custom",&#xA;      "tokenizer": "whitespace",&#xA;      "filter": [&#xA;        "lowercase",&#xA;        "asciifolding",&#xA;        "nGram_filter"&#xA;      ]&#xA;    },&#xA;    "whitespace_analyzer": {&#xA;      "type": "custom",&#xA;      "tokenizer": "whitespace",&#xA;      "filter": [&#xA;        "lowercase",&#xA;        "asciifolding"&#xA;      ]&#xA;    }&#xA;  }&#xA;</code></pre>&#xA;&#xA;<p>I'm using</p>&#xA;&#xA;<pre><code>"index_analyzer": "nGram_analyzer",&#xA;"search_analyzer": "whitespace_analyzer"&#xA;</code></pre>&#xA;&#xA;<p>But I'm not able to get the ngram on symbols like $, attaching the curl request</p>&#xA;&#xA;<pre><code>_analyze ? analyzer = nGram_analyzer ' -d '$100 '&#xA;{"tokens":[&#xA;  {"token":"10","start_offset":1,"end_offset":4,"type":"word","position":1},&#xA;  {"token":"100","start_offset":1,"end_offset":4,"type":"word","position":1},&#xA;  {"token":"00","start_offset":1,"end_offset":4,"type":"word","position":1}&#xA; ]}&#xA;</code></pre>&#xA;&#xA;<p>It is not giving me $ sign in the token. I will really appreciate if you can tell me where I'm going wrong.</p>&#xA;