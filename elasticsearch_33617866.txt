33617866
Completion Suggester TokenStream expanded Error
<p>I am using ES 1.7.2. My analyzer for filled_by_suggest field</p>&#xA;&#xA;<pre><code> "company_analyzer": {&#xA;    "tokenizer": "whitespace",&#xA;    "filter": [&#xA;      "shingle_filter"&#xA;    ]&#xA;  }&#xA;</code></pre>&#xA;&#xA;<p>shingle filter</p>&#xA;&#xA;<pre><code>"shingle_filter": { &#xA;    "type": "shingle", &#xA;    "min_shingle_size": 2, &#xA;    "max_shingle_size": 5&#xA;   }&#xA;</code></pre>&#xA;&#xA;<p>Mapping for field</p>&#xA;&#xA;<pre><code>"filed_by_suggest" : {"type" : "completion", "analyzer" : "company_analyzer"}&#xA;</code></pre>&#xA;&#xA;<p>When I do</p>&#xA;&#xA;<pre><code>PUT my_index/my_type/1&#xA;{&#xA;  "filed_by_suggest": "timothy M  Hogan - AZ Ctr  for Law in the Public Interest"&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>I get following Error</p>&#xA;&#xA;<pre><code>{&#xA;   "error": "IllegalArgumentException[TokenStream expanded to 1793 finite strings. Only &lt;= 256 finite strings are supported]",&#xA;   "status": 500&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>But when I try to index larger string like</p>&#xA;&#xA;<pre><code>PUT my_index/my_type/1&#xA;{&#xA;  "filed_by_suggest": "alliance telecommunications corp., hector communications corporation, golden west telecommunications cooperative, inc., splitrock telecom coop., inc., ollig utilities co., sioux valley telephone co., hills telephone co. inc., sleepy eye te"&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>This operation is successful. I know a bit about <strong>FST</strong> which is internally used by completion suggester. </p>&#xA;&#xA;<p>Could anyone please explain How tokens are expanded and How to address this problem?</p>&#xA;
<p>It depends on your analyzer.</p>&#xA;&#xA;<p>The input string, will be split into tokens by analyzer, you can test and count tokens with <code>_analyze</code> API.</p>&#xA;