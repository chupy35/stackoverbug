33374047
elasticsearch: How to reinitialize a node?
<p>elasticsearch 1.7.2 on CentOS</p>&#xA;&#xA;<p>We have a 3 node cluster that has been running fine. A networking problem caused the "B" node to lose network access. (It then turns out that the C node had the "minimum_master_nodes" as 1, not 2.)</p>&#xA;&#xA;<p>So we are now poking along with just the A node.</p>&#xA;&#xA;<p>We fixed the issues on the B and C nodes, but they refuse to come up and join the cluster. On B and C:</p>&#xA;&#xA;<pre><code># curl -XGET http://localhost:9200/_cluster/health?pretty=true&#xA;{&#xA;  "error" : "MasterNotDiscoveredException[waited for [30s]]",&#xA;  "status" : 503&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>The elasticsearch.yml is as follows (the name on "b" and "c" nodes are reflected in the node names on those systems, ALSO, the IP addys on each node reflect the other 2 nodes, HOWEVER, on the "c" node, the index.number_of_replicas was mistakenly set to 1.)</p>&#xA;&#xA;<pre><code>cluster.name: elasticsearch-prod&#xA;&#xA;node.name: "PROD-node-3a"&#xA;&#xA;node.master: true&#xA;&#xA;index.number_of_replicas: 2&#xA;&#xA;discovery.zen.minimum_master_nodes: 2&#xA;&#xA;discovery.zen.ping.multicast.enabled: false&#xA;&#xA;discovery.zen.ping.unicast.hosts: ["192.168.3.100", "192.168.3.101"]&#xA;</code></pre>&#xA;&#xA;<p>We have no idea why they won't join. They have network visibility to A, and A can see them. Each node correctly has the other two defined in "discovery.zen.ping.unicast.hosts:"</p>&#xA;&#xA;<p>On B and C, the log is very sparse, and tells us nothing:</p>&#xA;&#xA;<pre><code>    # cat elasticsearch.log&#xA;[2015-09-24 20:07:46,686][INFO ][node                     ] [The Profile] version[1.7.2], pid[866], build[e43676b/2015-09-14T09:49:53Z]&#xA;[2015-09-24 20:07:46,688][INFO ][node                     ] [The Profile] initializing ...&#xA;[2015-09-24 20:07:46,931][INFO ][plugins                  ] [The Profile] loaded [], sites []&#xA;[2015-09-24 20:07:47,054][INFO ][env                      ] [The Profile] using [1] data paths, mounts [[/ (rootfs)]], net usable_space [148.7gb], net total_space [157.3gb], types [rootfs]&#xA;[2015-09-24 20:07:50,696][INFO ][node                     ] [The Profile] initialized&#xA;[2015-09-24 20:07:50,697][INFO ][node                     ] [The Profile] starting ...&#xA;[2015-09-24 20:07:50,942][INFO ][transport                ] [The Profile] bound_address {inet[/0:0:0:0:0:0:0:0:9300]}, publish_address {inet[/10.181.3.138:9300]}&#xA;[2015-09-24 20:07:50,983][INFO ][discovery                ] [The Profile] elasticsearch/PojoIp-ZTXufX_Lxlwvdew&#xA;[2015-09-24 20:07:54,772][INFO ][cluster.service          ] [The Profile] new_master [The Profile][PojoIp-ZTXufX_Lxlwvdew][elastic-search-3c-prod-centos-case-48307][inet[/10.181.3.138:9300]], reason: zen-disco-join (elected_as_master)&#xA;[2015-09-24 20:07:54,801][INFO ][http                     ] [The Profile] bound_address {inet[/0:0:0:0:0:0:0:0:9200]}, publish_address {inet[/10.181.3.138:9200]}&#xA;[2015-09-24 20:07:54,802][INFO ][node                     ] [The Profile] started&#xA;[2015-09-24 20:07:54,880][INFO ][gateway                  ] [The Profile] recovered [0] indices into cluster_state&#xA;[2015-09-24 20:42:45,691][INFO ][node                     ] [The Profile] stopping ...&#xA;[2015-09-24 20:42:45,727][INFO ][node                     ] [The Profile] stopped&#xA;[2015-09-24 20:42:45,727][INFO ][node                     ] [The Profile] closing ...&#xA;[2015-09-24 20:42:45,735][INFO ][node                     ] [The Profile] closed&#xA;</code></pre>&#xA;&#xA;<p>How do we bring the whole beast to life?</p>&#xA;&#xA;<ul>&#xA;<li>Rebooting B and C makes no difference at all</li>&#xA;<li>I am hesitant to cycle A, as that is what our app is hitting...</li>&#xA;</ul>&#xA;
<p>Well, we do not know what brought it to life, but it kind of magically came back up.</p>&#xA;&#xA;<p>I believe that the shard reroute, (shown here: <a href="https://stackoverflow.com/q/33374494/147637">elasticsearch: Did I lose data when two of my three nodes went down?</a> ) caused the nodes to rejoin the cluster. Our theory is that node A, the only surviving node, was not a "healthy" master, because it knew that one shard (the "p" cut of shard 1, as spelled out here: <a href="https://stackoverflow.com/q/33374494/147637">elasticsearch: Did I lose data when two of my three nodes went down?</a> ) was not allocated.</p>&#xA;&#xA;<p>Since the master knew it was not intact, the other nodes declined to join the cluster, throwing the "MasterNotDiscoveredException"</p>&#xA;&#xA;<p>Once we got all the "p" shards assigned to the surviving A node, the other nodes joined up, and did the whole replicating dance.</p>&#xA;&#xA;<p><strong>HOWEVER Data was lost by allocating the shard like that.</strong>  We ultimately set up a new cluster, and are rebuilding the index (which takes several days).</p>&#xA;