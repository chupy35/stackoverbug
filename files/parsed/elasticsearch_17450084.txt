17450084 Setting refresh interval in Elasticsearch to improve io-wait?

My cluster shows a lot of io-waits (about 50%).

I do a lot of indexing and reindexing.

I thought maybe the re-indexing of lucene is the cause of much IO. Thought of
maybe upping the refresh_interval or maybe the index.translog options - is
that the right way to go?

My main problem is I do not know how to find out what my setting are.

In <http://www.elasticsearch.org/guide/reference/api/admin-indices-update-
settings/> it lists alot of options, none of which are available when I use:

    
    
    curl -xget 'http://localhost:9200/my_index/_settings'
    

It does not return values if using the defaults (According to kimchy's answer
on [this post](http://elasticsearch-users.115913.n3.nabble.com/Changing-the-
refresh-interval-on-running-nodes-td3020559.html#a4037476))

I only get the number of shards, replicas, which i set explicitly.  The
elasticsearch.yml file does not tell what the defaults are. How would I know
my changes took places, and what are the values now?

Help much appreciated as I cant find documentation for this.

running hot_threads, I got:

    
    
    > curl -XGET 'http://localhost:9200/_nodes/hot_threads?threads=5'
    ::: [Gardener][CR0qQbtBRyeU94hltnnE7A][inet[/10.154.148.151:9300]]{aws_availability_zone=us-east-1d}
    
       50.6% (253.2ms out of 500ms) cpu usage by thread 'elasticsearch[Gardener][search][T#20]'
         10/10 snapshots sharing following 8 elements
           sun.misc.Unsafe.park(Native Method)
           java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
           java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
           java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
           java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1068)
           java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
           java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
           java.lang.Thread.run(Thread.java:722)
    
       32.9% (164.5ms out of 500ms) cpu usage by thread 'elasticsearch[Gardener][search][T#12]'
         10/10 snapshots sharing following 8 elements
           sun.misc.Unsafe.park(Native Method)
           java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
           java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
           java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
           java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1068)
           java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
           java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
           java.lang.Thread.run(Thread.java:722)
    
       29.1% (145.5ms out of 500ms) cpu usage by thread 'elasticsearch[Gardener][search][T#8]'
         2/10 snapshots sharing following 20 elements
           org.apache.lucene.search.MultiTermQueryWrapperFilter.getDocIdSet(MultiTermQueryWrapperFilter.java:111)
           org.apache.lucene.search.ConstantScoreQuery$ConstantWeight.scorer(ConstantScoreQuery.java:131)
           org.apache.lucene.search.FilteredQuery$RandomAccessFilterStrategy.filteredScorer(FilteredQuery.java:533)
           org.apache.lucene.search.FilteredQuery$1.scorer(FilteredQuery.java:133)
           org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:609)
           org.elasticsearch.search.internal.ContextIndexSearcher.search(ContextIndexSearcher.java:161)
           org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:572)
           org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:524)
           org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:501)
           org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:345)
           org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:127)
           org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:239)
           org.elasticsearch.search.action.SearchServiceTransportAction.sendExecuteQuery(SearchServiceTransportAction.java:141)
           org.elasticsearch.action.search.type.TransportSearchQueryThenFetchAction$AsyncAction.sendExecuteFirstPhase(TransportSearchQueryThenFetchAction.java:80)
           org.elasticsearch.action.search.type.TransportSearchTypeAction$BaseAsyncAction.performFirstPhase(TransportSearchTypeAction.java:206)
           org.elasticsearch.action.search.type.TransportSearchTypeAction$BaseAsyncAction.performFirstPhase(TransportSearchTypeAction.java:193)
           org.elasticsearch.action.search.type.TransportSearchTypeAction$BaseAsyncAction$2.run(TransportSearchTypeAction.java:179)
           java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
           java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
           java.lang.Thread.run(Thread.java:722)
         8/10 snapshots sharing following 2 elements
           java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
           java.lang.Thread.run(Thread.java:722)
    
       26.5% (132.7ms out of 500ms) cpu usage by thread 'elasticsearch[Gardener][search][T#11]'
         2/10 snapshots sharing following 15 elements
           org.elasticsearch.search.internal.ContextIndexSearcher.search(ContextIndexSearcher.java:161)
           org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:572)
           org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:524)
           org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:501)
           org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:345)
           org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:127)
           org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:239)
           org.elasticsearch.search.action.SearchServiceTransportAction.sendExecuteQuery(SearchServiceTransportAction.java:141)
           org.elasticsearch.action.search.type.TransportSearchQueryThenFetchAction$AsyncAction.sendExecuteFirstPhase(TransportSearchQueryThenFetchAction.java:80)
           org.elasticsearch.action.search.type.TransportSearchTypeAction$BaseAsyncAction.performFirstPhase(TransportSearchTypeAction.java:206)
           org.elasticsearch.action.search.type.TransportSearchTypeAction$BaseAsyncAction.performFirstPhase(TransportSearchTypeAction.java:193)
           org.elasticsearch.action.search.type.TransportSearchTypeAction$BaseAsyncAction$2.run(TransportSearchTypeAction.java:179)
           java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
           java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
           java.lang.Thread.run(Thread.java:722)
         8/10 snapshots sharing following 8 elements
           sun.misc.Unsafe.park(Native Method)
           java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
           java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
           java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
           java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1068)
           java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
           java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
           java.lang.Thread.run(Thread.java:722)
    
        4.2% (21.1ms out of 500ms) cpu usage by thread 'elasticsearch[Gardener][bulk][T#4]'
         10/10 snapshots sharing following 9 elements
           sun.misc.Unsafe.park(Native Method)
           java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
           org.elasticsearch.common.util.concurrent.jsr166y.LinkedTransferQueue.awaitMatch(LinkedTransferQueue.java:706)
           org.elasticsearch.common.util.concurrent.jsr166y.LinkedTransferQueue.xfer(LinkedTransferQueue.java:615)
           org.elasticsearch.common.util.concurrent.jsr166y.LinkedTransferQueue.take(LinkedTransferQueue.java:1109)
           java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1068)
           java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
           java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
           java.lang.Thread.run(Thread.java:722)
    

Running with block and wait:

    
    
    > curl -XGET 'http://localhost:9200/_nodes/hot_threads?threads=3&type=wait'
    ::: [Gardener][CR0qQbtBRyeU94hltnnE7A][inet[/10.154.148.151:9300]]{aws_availability_zone=us-east-1d}
    
        0.0% (0s out of 500ms) wait usage by thread 'Reference Handler'
         10/10 snapshots sharing following 3 elements
           java.lang.Object.wait(Native Method)
           java.lang.Object.wait(Object.java:503)
           java.lang.ref.Reference$ReferenceHandler.run(Reference.java:133)
    
        0.0% (0s out of 500ms) wait usage by thread 'Finalizer'
         10/10 snapshots sharing following 4 elements
           java.lang.Object.wait(Native Method)
           java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:135)
           java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:151)
           java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:189)
    
        0.0% (0s out of 500ms) wait usage by thread 'Signal Dispatcher'
         unique snapshot
         unique snapshot
         unique snapshot
         unique snapshot
         unique snapshot
         unique snapshot
         unique snapshot
         unique snapshot
         unique snapshot
         unique snapshot
    
    > curl -XGET 'http://localhost:9200/_nodes/hot_threads?threads=3&type=block'
    ::: [Gardener][CR0qQbtBRyeU94hltnnE7A][inet[/10.154.148.151:9300]]{aws_availability_zone=us-east-1d}
    
        0.0% (0s out of 500ms) block usage by thread 'Reference Handler'
         10/10 snapshots sharing following 3 elements
           java.lang.Object.wait(Native Method)
           java.lang.Object.wait(Object.java:503)
           java.lang.ref.Reference$ReferenceHandler.run(Reference.java:133)
    
        0.0% (0s out of 500ms) block usage by thread 'Finalizer'
         10/10 snapshots sharing following 4 elements
           java.lang.Object.wait(Native Method)
           java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:135)
           java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:151)
           java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:189)
    
        0.0% (0s out of 500ms) block usage by thread 'Signal Dispatcher'
         unique snapshot
         unique snapshot
         unique snapshot
         unique snapshot
         unique snapshot
         unique snapshot
         unique snapshot
         unique snapshot
         unique snapshot
         unique snapshot
    

By default, `index.refresh_interval` is set to 1s. You can increase this
interval or disable automatic refresh by setting it to -1.

    
    
    curl -XPUT 'localhost:9200/my_index/_settings' -d '
    {
        "index" : {
            "refresh_interval" : -1
        }
    }
    '
    

However, before you start messing with settings I would suggest figuring out
the actual reason for such high I/O. Run
[hot_threads](http://www.elasticsearch.org/guide/reference/api/admin-cluster-
nodes-hot-threads/) request and check where threads are spending most of the
time.

