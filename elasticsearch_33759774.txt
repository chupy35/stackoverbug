33759774
elasticsearch: why is shard size missing in response to /_cat/shards
<p>We are seeing errors adding to the index, and when we ask for /_cat/shards we see this.</p>&#xA;&#xA;<p>The cluster status is green, and we see no other issues so far.</p>&#xA;&#xA;<p>What does the below mean?</p>&#xA;&#xA;<p><a href="https://i.stack.imgur.com/YPr4k.png" rel="nofollow noreferrer"><img src="https://i.stack.imgur.com/YPr4k.png" alt="Response to /_cat/shards"></a></p>&#xA;
<p>OK, we see why.</p>&#xA;&#xA;<p>We had to look in the log. (The cluster status is green, but the cluster is blown up... odd to us.)</p>&#xA;&#xA;<p>The problem is fielddata and memory. We thought by going to nodes with %100 more memory that we would solve this, but this turns out not to be the case.</p>&#xA;&#xA;<p>(We have code to monitor breakers, but that code has not yet deployed.)</p>&#xA;&#xA;<pre><code>[node-5a] [FIELDDATA] New used memory 641586695 [611.8mb] from field [PostalCode] would be lar&#xA;ger than configured breaker: 622775500 [593.9mb], breaking&#xA;[2015-11-16 18:22:33,777][DEBUG][action.search.type       ] [node-5a] [index_main][1], node[Kzhhh3XlRXmQpsSOEmNENw], [R], s[STARTED]:Failed to execute [org.elasticsearch.action.search.SearchRequest@43c19180] lastShard [true]&#xA;</code></pre>&#xA;&#xA;<p>We understand that the real fix is to go to doc_values. This has also been coded (but not yet deployed).</p>&#xA;&#xA;<p><strong>Bottom line:</strong> Another day, another catastrophic data loss in ES.  (Good thing we use SQL Server behind this.)</p>&#xA;&#xA;<p><strong>Product suggestion:</strong> When breakers trip, perhaps the cluster status should be something other than green?  We have long monitored cluster status, and only recently learned of breakers (and have to write a fair amount of code to manage breakers).</p>&#xA;&#xA;<hr>&#xA;&#xA;<p>Additional log info</p>&#xA;&#xA;<pre><code>[2015-11-16 18:22:33,769][WARN ][indices.breaker          ] [node-5a] [FIE&#xA;LDDATA] New used memory 641586695 [611.8mb] from field [PostalCode] would be larger than configured breaker: 622775500 [593.9mb], breaking&#xA;&#xA;[2015-11-16 18:22:33,777][DEBUG][action.search.type       ] [node-5a] [index_v5][1], node[Kzhhh3XlRXmQpsSOEmNENw], [R], s[STARTED]:&#xA;Failed to execute [org.elasticsearch.action.search.SearchRequest@43c19180] lastS&#xA;hard [true]&#xA;org.elasticsearch.search.query.QueryPhaseExecutionException: [index_v5_case_4905&#xA;7_2015_11_09][1]: query[filtered(+Hash:26444)-&gt;cache(_type:shipment)],from[0],si&#xA;ze[20],sort[&lt;custom:"PostalCode": org.elasticsearch.index.fielddata.fieldcompara&#xA;tor.BytesRefFieldComparatorSource@3b41b3cb&gt;!]: Query Failed [Failed to execute m&#xA;ain query]&#xA;        at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:163&#xA;...&#xA;&#xA;Caused by: org.elasticsearch.common.breaker.CircuitBreakingException: [FIELDDATA] Data too large, data for [PostalCode] would be larger than limit of [622775500&#xA;</code></pre>&#xA;