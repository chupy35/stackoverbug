33389713
Why search_analyzer (keyword) does not work with edgeNgram index_analyer?
<p>I have the following mapping:</p>&#xA;&#xA;<pre><code>analyzer:&#xA;    edge_ngram_analyzer:&#xA;        type: custom&#xA;        tokenizer: edge_ngram&#xA;tokenizer:&#xA;    edge_ngram:&#xA;        type : edgeNGram&#xA;        min_gram : 2&#xA;        max_gram : 20&#xA;&#xA;productCode:&#xA;    type: string&#xA;    inxed_analyzer: edge_ngram_analyzer&#xA;    search_analyzer: keyword&#xA;</code></pre>&#xA;&#xA;<p>Search string is <code>AH.20</code>&#xA;Index analyzer's tokens: <code>AH</code>, <code>AH.</code>, <code>AH.2</code>, <code>AH.20</code>&#xA;Search analyzer's tokens: <code>AH.20</code></p>&#xA;&#xA;<p>Query:</p>&#xA;&#xA;<pre><code> {&#xA;  "query": {&#xA;    "bool": {&#xA;      "must": [&#xA;        {&#xA;          "query_string": {&#xA;            "default_field": "product.productCode",&#xA;            "query": "AH.20"&#xA;          }&#xA;        }&#xA;      ]&#xA;    }&#xA;  }&#xA;} &#xA;</code></pre>&#xA;&#xA;<p>But it returns nothing. What is wrong with the mapping?&#xA;PS when I don't use search_analyzer, elasticsearch returns correct results (I'm sure that ES breaks search string to tokens <code>AH</code>, <code>20</code> using <code>standard</code> tokenizer)</p>&#xA;
<p>You problem, unless is a typo, is in your mapping definition:</p>&#xA;&#xA;<pre><code>inxed_analyzer: edge_ngram_analyzer&#xA;</code></pre>&#xA;&#xA;<p>It should be:</p>&#xA;&#xA;<pre><code>index_analyzer: edge_ngram_analyzer&#xA;</code></pre>&#xA;