33595060
How do I configure Elasticsearch to find substrings at the beginning OR at the end of a word (but not in middle)?
<p>I'm starting to learn Elasticsearch and now I am trying to write my first analyser configuration. What I want to achieve is that substrings are found if they are at the beginning or ending of a word. If I have the word "stackoverflow" and I search for "stack" I want to find it and when I search for "flow" I want to find it, but I do <em>not</em> want to find it when searching for "ackov" (in my use case this would not make sense).</p>&#xA;&#xA;<p>I know there is the "Edge n gram tokenizer", but one analyser can only have one tokenizer and the edge n-gram can either be front or back (but not both at the same time).</p>&#xA;&#xA;<p>And if I understood correctly, applying both version of the "Edge ngram <em>filter</em>" (front and back) to the analyzer, then I would not find either, because both filters need to return true, isn't it? Because "stack" wouldn't be in the ending of the word, so the back edge n gram filter would return false and the word "stackoverflow" would not be found.</p>&#xA;&#xA;<p>So, how do I configure my analyzer to find substrings either in the end or in the beginning of a word, but not in the middle?</p>&#xA;
<p>What can be done is to define two analyzers, one for matching at the start of a string and another to match at the end of a string. In the index settings below, I named the former one <code>prefix_edge_ngram_analyzer</code> and the latter one <code>suffix_edge_ngram_analyzer</code>. Those two analyzers can be applied to a multi-field string field to the <code>text.prefix</code> sub-field, respectively to the <code>text.suffix</code> string field.</p>&#xA;&#xA;<pre><code>{&#xA;  "settings": {&#xA;    "analysis": {&#xA;      "analyzer": {&#xA;        "prefix_edge_ngram_analyzer": {&#xA;          "tokenizer": "prefix_edge_ngram_tokenizer",&#xA;          "filter": ["lowercase"]&#xA;        },&#xA;        "suffix_edge_ngram_analyzer": {&#xA;          "tokenizer": "keyword",&#xA;          "filter" : ["lowercase","reverse","suffix_edge_ngram_filter","reverse"]&#xA;        }&#xA;      },&#xA;      "tokenizer": {&#xA;        "prefix_edge_ngram_tokenizer": {&#xA;          "type": "edgeNGram",&#xA;          "min_gram": "2",&#xA;          "max_gram": "25"&#xA;        }&#xA;      },&#xA;      "filter": {&#xA;        "suffix_edge_ngram_filter": {&#xA;          "type": "edgeNGram",&#xA;          "min_gram": 2,&#xA;          "max_gram": 25&#xA;        }&#xA;      }&#xA;    }&#xA;  },&#xA;  "mappings": {&#xA;    "test_type": {&#xA;      "properties": {&#xA;        "text": {&#xA;          "type": "string",&#xA;          "fields": {&#xA;            "prefix": {&#xA;              "type": "string",&#xA;              "analyzer": "prefix_edge_ngram_analyzer"&#xA;            },&#xA;            "suffix": {&#xA;              "type": "string",&#xA;              "analyzer": "suffix_edge_ngram_analyzer"&#xA;            }&#xA;          }&#xA;        }&#xA;      }&#xA;    }&#xA;  }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Then let's say we index the following test document:</p>&#xA;&#xA;<pre><code>PUT test_index/test_type/1&#xA;{ "text": "stackoverflow" }&#xA;</code></pre>&#xA;&#xA;<p>We can then search either by prefix or suffix using the following queries:</p>&#xA;&#xA;<pre><code># input is "stack" =&gt; 1 result&#xA;GET test_index/test_type/_search?q=text.prefix:stack OR text.suffix:stack&#xA;&#xA;# input is "flow" =&gt; 1 result&#xA;GET test_index/test_type/_search?q=text.prefix:flow OR text.suffix:flow&#xA;&#xA;# input is "ackov" =&gt; 0 result&#xA;GET test_index/test_type/_search?q=text.prefix:ackov OR text.suffix:ackov&#xA;</code></pre>&#xA;&#xA;<p>Another way to query with the query DSL:</p>&#xA;&#xA;<pre><code>POST test_index/test_type/_search&#xA;{&#xA;   "query": {&#xA;      "multi_match": {&#xA;         "query": "stack",&#xA;         "fields": [ "text.*" ]&#xA;      }&#xA;   }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p><strong>UPDATE</strong></p>&#xA;&#xA;<p>If you already have a string field, you can "upgrade" it to a multi-field and create the two required sub-fields with their analyzers. The way to do this would be to do this in order:</p>&#xA;&#xA;<ol>&#xA;<li><p>Close your index in order to create the analyzers</p>&#xA;&#xA;<pre><code>POST test_index/_close&#xA;</code></pre></li>&#xA;<li><p>Update the index settings</p>&#xA;&#xA;<pre><code>PUT test_index/_settings&#xA;{&#xA;"analysis": {&#xA;  "analyzer": {&#xA;    "prefix_edge_ngram_analyzer": {&#xA;      "tokenizer": "prefix_edge_ngram_tokenizer",&#xA;      "filter": ["lowercase"]&#xA;    },&#xA;    "suffix_edge_ngram_analyzer": {&#xA;      "tokenizer": "keyword",&#xA;      "filter" : ["lowercase","reverse","suffix_edge_ngram_filter","reverse"]&#xA;    }&#xA;  },&#xA;  "tokenizer": {&#xA;    "prefix_edge_ngram_tokenizer": {&#xA;      "type": "edgeNGram",&#xA;      "min_gram": "2",&#xA;      "max_gram": "25"&#xA;    }&#xA;  },&#xA;  "filter": {&#xA;    "suffix_edge_ngram_filter": {&#xA;      "type": "edgeNGram",&#xA;      "min_gram": 2,&#xA;      "max_gram": 25&#xA;    }&#xA;  }&#xA;}&#xA;}&#xA;</code></pre></li>&#xA;<li><p>Re-open your index</p>&#xA;&#xA;<pre><code>POST test_index/_open&#xA;</code></pre></li>&#xA;<li><p>Finally, update the mapping of your text field</p>&#xA;&#xA;<pre><code>PUT test_index/_mapping/test_type&#xA;{&#xA;  "properties": {&#xA;    "text": {&#xA;      "type": "string",&#xA;      "fields": {&#xA;        "prefix": {&#xA;          "type": "string",&#xA;          "analyzer": "prefix_edge_ngram_analyzer"&#xA;        },&#xA;        "suffix": {&#xA;          "type": "string",&#xA;          "analyzer": "suffix_edge_ngram_analyzer"&#xA;        }&#xA;      }&#xA;    }&#xA;  }&#xA;}&#xA;</code></pre></li>&#xA;<li><p>You still need to re-index all your documents in order for the new sub-fields <code>text.prefix</code> and <code>text.suffix</code> to be populated and analyzed.</p></li>&#xA;</ol>&#xA;