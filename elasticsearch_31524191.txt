31524191
Is it possible to chain fquery filters in elastic search with exact matches?
<p>I have been having trouble writing a method that will take in various search parameters in elasticsearch. I was working with queries that looked like this: </p>&#xA;&#xA;<pre><code>body: &#xA;  {query:&#xA;    {filtered: &#xA;      {filter: &#xA;        {and: &#xA;          [&#xA;          {term: {some_term: "foo"}}, &#xA;          {term: {is_visible: true}}, &#xA;          {term: {"term_two": "something"}}]&#xA;         }&#xA;      }&#xA;    }&#xA;  }&#xA;</code></pre>&#xA;&#xA;<p>Using this syntax I thought I could chain these terms together and programatically generate these queries. I was using simple strings and if there was a term like "person_name" I could split the query into two and say "where person_name match 'JOHN'" and where person_name match 'SMITH'" getting accurate results. </p>&#xA;&#xA;<p>However, I just came across the "fquery" upon asking this question: &#xA;<a href="https://stackoverflow.com/questions/31442499/escaping-slash-in-elasticsearch">Escaping slash in elasticsearch</a></p>&#xA;&#xA;<p>I was not able to use this "and"/"term" filter searching a value with slashes in it, so I learned that I can use fquery to search for the full value, like this </p>&#xA;&#xA;<pre><code> "fquery": {&#xA;     "query": {&#xA;        "match": {&#xA;           "by_line": "John Smith"&#xA;</code></pre>&#xA;&#xA;<p>But how can I search like this for multiple items? IT seems that when i combine fquery and my filtered/filter/and/term queries, my "and" term queries are ignored. What is the best practice for making nested / chained queries using elastic search ? </p>&#xA;&#xA;<p>As in the comment below, yes I can just add fquery to the "and" block like so </p>&#xA;&#xA;<pre><code>{:filtered=&gt;&#xA;  {:filter=&gt;&#xA;    {:and=&gt;[&#xA;      {:term=&gt;{:is_visible=&gt;true}}, &#xA;      {:term=&gt;{:is_private=&gt;false}}, &#xA;      {:fquery=&gt;&#xA;        {:query=&gt;{:match=&gt;{:sub_location=&gt;"New JErsey"}}}}]}}}&#xA;</code></pre>&#xA;&#xA;<p>Why would elasticsearch also return results with "sub_location" = "new York"? I would like to only return "new jersey" here. </p>&#xA;
<p>A <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-match-query.html" rel="nofollow">match query</a> analyzes the input and by default it is a <code>boolean OR</code> query if there are multiple terms after the analysis. In your case, "New JErsey" gets analyzed into the terms "new" and "jersey". The <code>match</code> query that you are using will search for documents in which the <strong>indexed</strong> value of field "sub_location" is either "new" or "jersey". That is why your query also matches documents where the value of field "sub_location" is "new York" because of the common term "new". </p>&#xA;&#xA;<p>To only match for "new jersey", you can use the following version of the <code>match</code> query:</p>&#xA;&#xA;<pre><code>{&#xA;   "query": {&#xA;      "match": {&#xA;         "sub_location": {&#xA;            "query": "New JErsey",&#xA;            "operator": "and"&#xA;         }&#xA;      }&#xA;   }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>This will not match documents where the value of field "sub_location" is "New York". <strong>But</strong>, it will match documents where the value of field "sub_location" is say "York New" because the query finally translates into a boolean query like <code>"York" AND "New"</code>. If you are fine with this behaviour, well and good, else read further.</p>&#xA;&#xA;<p>All these issues arise because you are using the default analyzer for the field "sub_location" which breaks tokens at word boundaries and indexes them. If you really do not care about partial matches and want to always match the entire string, you can make use of <a href="https://www.elastic.co/guide/en/elasticsearch/guide/current/custom-analyzers.html" rel="nofollow">custom analyzers</a> to use <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-keyword-tokenizer.html" rel="nofollow">Keyword Tokenizer</a> and <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-lowercase-tokenfilter.html" rel="nofollow">Lowercase Token Filter</a>. Mind you, going ahead with this approach will need you to re-index all your documents again.</p>&#xA;