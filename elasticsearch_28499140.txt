28499140
regular expression in elasticsearch?
<p>what should be the regular expression pattern for tokenizer in elasticsearch for matching c# and c++ each separately . Right now we have one analyzer for this but when ever we are trying to search c# it is showing c++ also as a match and vice versa.</p>&#xA;
<p>Assuming I'm understanding you correctly, one thing you can do is set up an analyzer that just tokenizes on whitespace. The default <a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/analysis-standard-analyzer.html" rel="nofollow">standard analyzer</a> tokenizes on symbols as well as whitespace, so <code>"c++"</code> and <code>"c#"</code> both get turned into the term <code>"c"</code>, so both documents will match a search for one or the other.</p>&#xA;&#xA;<p>One way around this (though it might cause you other headaches), is to use an analyzer like this:</p>&#xA;&#xA;<pre><code>"whitespace_analyzer": {&#xA;   "type": "custom",&#xA;   "tokenizer": "whitespace",&#xA;   "filter": [&#xA;      "lowercase",&#xA;      "asciifolding"&#xA;   ]&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Or, in a full toy example, I can set up an index like:</p>&#xA;&#xA;<pre><code>PUT /test_index&#xA;{&#xA;   "settings": {&#xA;      "number_of_shards": 1,&#xA;      "number_of_replicas": 0,&#xA;      "analysis": {&#xA;         "analyzer": {&#xA;            "whitespace_analyzer": {&#xA;               "type": "custom",&#xA;               "tokenizer": "whitespace",&#xA;               "filter": [&#xA;                  "lowercase",&#xA;                  "asciifolding"&#xA;               ]&#xA;            }&#xA;         }&#xA;      }&#xA;   },&#xA;   "mappings": {&#xA;      "doc": {&#xA;         "properties": {&#xA;            "text_field": {&#xA;               "type": "string",&#xA;               "analyzer": "whitespace_analyzer"&#xA;            }&#xA;         }&#xA;      }&#xA;   }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>then add a few docs via the <a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/docs-bulk.html" rel="nofollow"><code>bulk api</code></a>:</p>&#xA;&#xA;<pre><code>POST /test_index/_bulk&#xA;{"index":{"_index":"test_index","_type":"doc", "_id":1}}&#xA;{"text_field": "some text with C++"}&#xA;{"index":{"_index":"test_index","_type":"doc", "_id":2}}&#xA;{"text_field": "some text with C#"}&#xA;{"index":{"_index":"test_index","_type":"doc", "_id":3}}&#xA;{"text_field": "some text with Objective-C"}&#xA;</code></pre>&#xA;&#xA;<p>Now a search for <code>"C++"</code> only gives me back the document that contains that term:</p>&#xA;&#xA;<pre><code>POST /test_index/_search&#xA;{&#xA;    "query": {&#xA;        "match": {&#xA;           "text_field": "C++"&#xA;        }&#xA;    }&#xA;}&#xA;...&#xA;{&#xA;   "took": 2,&#xA;   "timed_out": false,&#xA;   "_shards": {&#xA;      "total": 1,&#xA;      "successful": 1,&#xA;      "failed": 0&#xA;   },&#xA;   "hits": {&#xA;      "total": 1,&#xA;      "max_score": 0.70273256,&#xA;      "hits": [&#xA;         {&#xA;            "_index": "test_index",&#xA;            "_type": "doc",&#xA;            "_id": "1",&#xA;            "_score": 0.70273256,&#xA;            "_source": {&#xA;               "text_field": "some text with C++"&#xA;            }&#xA;         }&#xA;      ]&#xA;   }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>and likewise with <code>"C#"</code></p>&#xA;&#xA;<pre><code>POST /test_index/_search&#xA;{&#xA;    "query": {&#xA;        "match": {&#xA;           "text_field": "C#"&#xA;        }&#xA;    }&#xA;}&#xA;...&#xA;{&#xA;   "took": 1,&#xA;   "timed_out": false,&#xA;   "_shards": {&#xA;      "total": 1,&#xA;      "successful": 1,&#xA;      "failed": 0&#xA;   },&#xA;   "hits": {&#xA;      "total": 1,&#xA;      "max_score": 0.70273256,&#xA;      "hits": [&#xA;         {&#xA;            "_index": "test_index",&#xA;            "_type": "doc",&#xA;            "_id": "2",&#xA;            "_score": 0.70273256,&#xA;            "_source": {&#xA;               "text_field": "some text with C#"&#xA;            }&#xA;         }&#xA;      ]&#xA;   }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>This solution may or may not end up giving you what you want, because it won't tokenize on punctuation either.</p>&#xA;&#xA;<p>Here is the code I used:</p>&#xA;&#xA;<p><a href="http://sense.qbox.io/gist/92871671ea7313356cbbd1ea900c3d55944bd20b" rel="nofollow">http://sense.qbox.io/gist/92871671ea7313356cbbd1ea900c3d55944bd20b</a></p>&#xA;&#xA;<p><strong>EDIT:</strong> Here is a slightly more advanced solution that can help solve the punctuation problem. I got the idea from <a href="http://www.fullscale.co/blog/2013/03/04/preserving_specific_characters_during_tokenizing_in_elasticsearch.html" rel="nofollow">this article</a>. The basic idea is that you can declare certain symbol characters to be alpha-numeric characters.</p>&#xA;&#xA;<p>So I create the index using a custom <a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/analysis-tokenfilters.html" rel="nofollow">token filter</a>, then add the same three docs plus another one that the previous solution would not handle correctly:</p>&#xA;&#xA;<pre><code>DELETE /test_index&#xA;&#xA;PUT /test_index&#xA;{&#xA;   "settings": {&#xA;      "number_of_shards": 1,&#xA;      "number_of_replicas": 0,&#xA;      "analysis": {&#xA;         "filter": {&#xA;            "symbol_filter": {&#xA;               "type": "word_delimiter",&#xA;               "type_table": [&#xA;                  "# =&gt; ALPHANUM",&#xA;                  "+ =&gt; ALPHANUM",&#xA;                  "@ =&gt; ALPHANUM"&#xA;               ]&#xA;            }&#xA;         },&#xA;         "analyzer": {&#xA;            "whitespace_analyzer": {&#xA;               "type": "custom",&#xA;               "tokenizer": "whitespace",&#xA;               "filter": [&#xA;                  "lowercase",&#xA;                  "asciifolding",&#xA;                  "symbol_filter"&#xA;               ]&#xA;            }&#xA;         }&#xA;      }&#xA;   },&#xA;   "mappings": {&#xA;      "doc": {&#xA;         "properties": {&#xA;            "text_field": {&#xA;               "type": "string",&#xA;               "analyzer": "whitespace_analyzer"&#xA;            }&#xA;         }&#xA;      }&#xA;   }&#xA;}&#xA;&#xA;POST /test_index/_bulk&#xA;{"index":{"_index":"test_index","_type":"doc", "_id":1}}&#xA;{"text_field": "some text with C++"}&#xA;{"index":{"_index":"test_index","_type":"doc", "_id":2}}&#xA;{"text_field": "some text with C#"}&#xA;{"index":{"_index":"test_index","_type":"doc", "_id":3}}&#xA;{"text_field": "some text with Objective-C"}&#xA;{"index":{"_index":"test_index","_type":"doc", "_id":4}}&#xA;{"text_field": "some text with Objective-C, C#, and C++."}&#xA;</code></pre>&#xA;&#xA;<p>Now querying for <code>"C++"</code> will return both the documents that contain that token:</p>&#xA;&#xA;<pre><code>POST /test_index/_search&#xA;{&#xA;    "query": {&#xA;        "match": {&#xA;           "text_field": "C++"&#xA;        }&#xA;    }&#xA;}&#xA;...&#xA;{&#xA;   "took": 1,&#xA;   "timed_out": false,&#xA;   "_shards": {&#xA;      "total": 1,&#xA;      "successful": 1,&#xA;      "failed": 0&#xA;   },&#xA;   "hits": {&#xA;      "total": 2,&#xA;      "max_score": 0.643841,&#xA;      "hits": [&#xA;         {&#xA;            "_index": "test_index",&#xA;            "_type": "doc",&#xA;            "_id": "1",&#xA;            "_score": 0.643841,&#xA;            "_source": {&#xA;               "text_field": "some text with C++"&#xA;            }&#xA;         },&#xA;         {&#xA;            "_index": "test_index",&#xA;            "_type": "doc",&#xA;            "_id": "4",&#xA;            "_score": 0.40240064,&#xA;            "_source": {&#xA;               "text_field": "some text with Objective-C, C#, and C++."&#xA;            }&#xA;         }&#xA;      ]&#xA;   }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Here is the code for this one:</p>&#xA;&#xA;<p><a href="http://sense.qbox.io/gist/5c583b4e99b8f3b088925ccdb894695aa0c257cb" rel="nofollow">http://sense.qbox.io/gist/5c583b4e99b8f3b088925ccdb894695aa0c257cb</a></p>&#xA;