31107272
elasticsearch 1.6 field norm calculation with shingle filter
<p>I am trying to understand the fieldnorm calculation in elasticsearch (1.6) for documents indexed with a shingle analyzer - it does not seem to include shingled terms. If so, is it possible to configure the calculation to include the shingled terms? Specifically, this is the analyzer I used:</p>&#xA;&#xA;<pre><code>{&#xA;  "index" : {&#xA;    "analysis" : {&#xA;        "filter" : {&#xA;            "shingle_filter" : {&#xA;                "type" : "shingle",&#xA;                "max_shingle_size" : 3&#xA;            }&#xA;        },&#xA;        "analyzer" : {&#xA;            "my_analyzer" : {&#xA;                "type" : "custom",&#xA;                "tokenizer" : "standard",&#xA;                "filter" : ["word_delimiter", "lowercase", "shingle_filter"]&#xA;            }&#xA;        }  &#xA;    }&#xA; }&#xA;</code></pre>&#xA;&#xA;<p>}</p>&#xA;&#xA;<p>This is the mapping used:</p>&#xA;&#xA;<pre><code>{&#xA;    "docs": {&#xA;        "properties": {&#xA;            "text" : {"type": "string", "analyzer" : "my_analyzer"}&#xA;        }&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>And I posted a few documents:</p>&#xA;&#xA;<pre><code>{"text" : "the"}&#xA;{"text" : "the quick"}&#xA;{"text" : "the quick brown"}&#xA;{"text" : "the quick brown fox jumps"}&#xA;...&#xA;</code></pre>&#xA;&#xA;<p>When using the following query with the explain API,</p>&#xA;&#xA;<pre><code>{&#xA;    "query": {&#xA;        "match": {&#xA;            "text" : "the"&#xA;        }&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>I get the following fieldnorms (other details omitted for brevity):</p>&#xA;&#xA;<pre><code>"_source": {&#xA;    "text": "the quick"&#xA;},&#xA;"_explanation": {&#xA;    "value": 0.625,&#xA;    "description": "fieldNorm(doc=0)"&#xA;}&#xA;&#xA;"_source": {&#xA;    "text": "the quick brown fox jumps over the"&#xA;},&#xA;"_explanation": {&#xA;    "value": 0.375,&#xA;    "description": "fieldNorm(doc=0)"&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>The values seem to suggest that ES sees 2 terms for the 1st document ("the quick") and 7 terms for the 2nd document ("the quick brown fox jumps over the"), excluding the shingles. Is it possible to configure ES to calculate field norm with the shingled terms too (ie. all terms returned by the analyzer)?</p>&#xA;
<p>You would need to customize the <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/index-modules-similarity.html#default-similarity" rel="nofollow">default similarity</a> by disabling the discount overlap flag.</p>&#xA;&#xA;<p>Example:</p>&#xA;&#xA;<pre><code>{&#xA;  "index" : {&#xA;      "similarity" : {&#xA;          "no_overlap" : {&#xA;            "type" : "default",&#xA;            "discount_overlaps" : false&#xA;          } &#xA;    },&#xA;    "analysis" : {&#xA;        "filter" : {&#xA;            "shingle_filter" : {&#xA;                "type" : "shingle",&#xA;                "max_shingle_size" : 3&#xA;            }&#xA;        },&#xA;        "analyzer" : {&#xA;            "my_analyzer" : {&#xA;                "type" : "custom",&#xA;                "tokenizer" : "standard",&#xA;                "filter" : ["word_delimiter", "lowercase", "shingle_filter"]&#xA;            }&#xA;        }  &#xA;    }&#xA; }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Mapping:</p>&#xA;&#xA;<pre><code>{&#xA;    "docs": {&#xA;        "properties": {&#xA;            "text" : {"type": "string", "analyzer" : "my_analyzer", "similarity&#xA;" : "no_overlap"}&#xA;        }&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>To expand further:</p>&#xA;&#xA;<p>By default overlaps i.e Tokens with 0 position increment are ignored when computing norm</p>&#xA;&#xA;<p>Example below shows the postion of tokens generated by the  "<em>my_analyzer</em>" described in OP :</p>&#xA;&#xA;<pre><code>get &lt;index_name&gt;/_analyze?field=text&amp;text=the quick&#xA;&#xA;{&#xA;   "tokens": [&#xA;      {&#xA;         "token": "the",&#xA;         "start_offset": 0,&#xA;         "end_offset": 3,&#xA;         "type": "&lt;ALPHANUM&gt;",&#xA;         "position": 1&#xA;      },&#xA;      {&#xA;         "token": "the quick",&#xA;         "start_offset": 0,&#xA;         "end_offset": 9,&#xA;         "type": "shingle",&#xA;         "position": 1&#xA;      },&#xA;      {&#xA;         "token": "quick",&#xA;         "start_offset": 4,&#xA;         "end_offset": 9,&#xA;         "type": "&lt;ALPHANUM&gt;",&#xA;         "position": 2&#xA;      }&#xA;   ]&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>According to <a href="http://lucene.apache.org/core/4_10_4/core/org/apache/lucene/search/similarities/DefaultSimilarity.html#lengthNorm(org.apache.lucene.index.FieldInvertState)" rel="nofollow">lucene documentation</a> the <em>length norm</em> calculation for default similarity is implemented as follows :</p>&#xA;&#xA;<pre><code>state.getBoost()*lengthNorm(numTerms)&#xA;</code></pre>&#xA;&#xA;<p>where <em>numTerms</em> is </p>&#xA;&#xA;<pre><code>if setDiscountOverlaps(boolean) is false&#xA;  FieldInvertState.getLength() &#xA;else &#xA;   FieldInvertState.getLength() - FieldInvertState.getNumOverlap()&#xA;</code></pre>&#xA;