32462809
Elasticsearch unable to create native thread
<p>I am running an elasticsearch cluster that consists of a single node. At one point, it crashed with the following message: "failed to prepare/warm" and the following exception: </p>&#xA;&#xA;<pre><code>java.lang.OutOfMemoryError: unable to create new native thread&#xA;    at java.lang.Thread.start0(Native Method) [na:1.8.0_45]&#xA;    at java.lang.Thread.start(Thread.java:714) [na:1.8.0_45]&#xA;    at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:950) [na:1.8.0_45]&#xA;    at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1368) [na:1.8.0_45]&#xA;...&#xA;</code></pre>&#xA;&#xA;<p>So, it appears that the OS (Windows 32-bit) was unable to create a thread, in which case I'm assuming it had exceeded the maximum number of threads possible in this process.</p>&#xA;&#xA;<p>I was looking over the elasticsearch <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-threadpool.html" rel="nofollow">Thread Pool documentation</a>, and it sounds like the problem is that some of these thread pools are, by default, unbounded. Plus, since this is a 32-bit machine, it is more likely to run out of threads. </p>&#xA;&#xA;<p>My question is: (1) Does this seem like a valid assessment? and (2) The documentation mentions that some of the pools are by default, "scaling". But it does not then describe what "scaling" means. Is there a description somewhere of that?</p>&#xA;&#xA;<p>Is it possible to leaving the setting at scaling, but specify a maximum number of threads to allocate? Would it be best to specify these settings with a "fixed" size thread pool?</p>&#xA;
<p>No, I think your assessment is backwards: Your Elastic instance ran out of memory. It did so while trying to create a new thread, but that is most likely a coincidence.</p>&#xA;&#xA;<p>What's your <code>Xmx</code> setting for the Elastic JVM?</p>&#xA;