33169924
Inserting large events in Elasticsearch fails
<p>When I insert large events into Elasticsearch, I receive an error:</p>&#xA;&#xA;<pre><code>java.lang.IllegalArgumentException: Document contains at least one immense term in field="_all" (whose UTF8 encoding is longer than the max length 32766), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: '[&lt;skipped&gt;]...', original message: bytes can be at most 32766 in length; got 53021&#xA;</code></pre>&#xA;&#xA;<p>I use the keyword-analyzer since I don't want ES to split fields into separate tokens so this is my index-definition:</p>&#xA;&#xA;<pre><code>{&#xA;      "index" : {&#xA;          "analysis" : {&#xA;              "analyzer" : {&#xA;                  "default" : {&#xA;                      "type" : "keyword"&#xA;                  }&#xA;              }&#xA;          }&#xA;      }&#xA;  }&#xA;</code></pre>&#xA;&#xA;<p>How can I make ES accepting my large events but still have the keyword-analyzer as default?</p>&#xA;
<p>All field-values are added into the _all-field by default and since that fields also uses the keyword-analyzer, that field will contain <em>one</em> token of size 50kB, which is a bit over the limit. The limit doesn't seem to be configurable.</p>&#xA;&#xA;<p>One solution is to specify a different analyzer for that field:</p>&#xA;&#xA;<pre><code>  curl -XPUT ${ES_HOST}:${ES_PORT}/${ES_INDEX}/${ES_TYPE}/_mapping  -d "&#xA;  {&#xA;      "${ES_TYPE}": {&#xA;          "_all\: { "analyzer": "standard" }&#xA;      }&#xA;  }"&#xA;</code></pre>&#xA;