30930428
How to check the tokens generated for different tokenizers in Elasticsearch
<p>I have been using different type of tokenizers for test and demonstration purposes. I need to check how a particular text field is tokenized using different tokenizers and also see the tokens generated.</p>&#xA;&#xA;<p>How can I achieve that?</p>&#xA;
<p>You can use the <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-analyze.html" rel="noreferrer"><code>_analyze</code> endpoint</a> for this purpose.</p>&#xA;&#xA;<p>For instance, using the standard analyzer, you can analyze <code>this is a test</code> like this</p>&#xA;&#xA;<pre><code>curl -XGET 'localhost:9200/_analyze?analyzer=standard&amp;pretty' -d 'this is a test'&#xA;</code></pre>&#xA;&#xA;<p>And this produces the following tokens:</p>&#xA;&#xA;<pre><code>{&#xA;  "tokens" : [ {&#xA;    "token" : "this",&#xA;    "start_offset" : 0,&#xA;    "end_offset" : 4,&#xA;    "type" : "&lt;ALPHANUM&gt;",&#xA;    "position" : 1&#xA;  }, {&#xA;    "token" : "is",&#xA;    "start_offset" : 5,&#xA;    "end_offset" : 7,&#xA;    "type" : "&lt;ALPHANUM&gt;",&#xA;    "position" : 2&#xA;  }, {&#xA;    "token" : "a",&#xA;    "start_offset" : 8,&#xA;    "end_offset" : 9,&#xA;    "type" : "&lt;ALPHANUM&gt;",&#xA;    "position" : 3&#xA;  }, {&#xA;    "token" : "test",&#xA;    "start_offset" : 10,&#xA;    "end_offset" : 14,&#xA;    "type" : "&lt;ALPHANUM&gt;",&#xA;    "position" : 4&#xA;  } ]&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Of course, you can use any of the <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis.html" rel="noreferrer">existing analyzers</a> and you can also specify tokenizers using the <code>tokenizer</code> parameter, token filters using the <code>token_filters</code>parameter and character filters using the <code>char_filters</code> parameter. For instance, analyzing the HTML <code>curl -XGET 'localhost:9200/_analyze?tokenizer=keyword&amp;token_filters=lowercase&amp;char_filters=html_strip' -d 'THIS is a &lt;b&gt;TEST&lt;/b&gt;'</code> using the standard analyzer, the <code>keyword</code> tokenizer, the <code>lowercase</code> token filter and the <code>html_strip</code> character filter yields this, i.e. a lowercase single token without the HTML markup:</p>&#xA;&#xA;<pre><code>curl -XGET 'localhost:9200/_analyze?tokenizer=keyword&amp;token_filters=lowercase&amp;char_filters=html_strip' -d 'THIS is a &lt;b&gt;TEST&lt;/b&gt;'&#xA;&#xA;{&#xA;  "tokens" : [ {&#xA;    "token" : "this is a test",&#xA;    "start_offset" : 0,&#xA;    "end_offset" : 21,&#xA;    "type" : "word",&#xA;    "position" : 1&#xA;  } ]&#xA;}&#xA;</code></pre>&#xA;
<p>Apart from what @Val have mentioned you can try out the <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-termvectors.html" rel="nofollow">term vecto</a>r,if you are intending to study the working of tokenisers.You can try out something like this just for examining the tokenisation happening in a field</p>&#xA;&#xA;<pre><code>GET /index-name/type-name/doc-id/_termvector?fields=field-to-be-examined&#xA;</code></pre>&#xA;&#xA;<p>To know more about tokenisers and their operations you can refer this <a href="http://blog.qbox.io/an-introduction-to-ngrams-in-elasticsearch" rel="nofollow">blog</a></p>&#xA;