33906032
filterby, groupby unique field value, sum aggregation, orderby chain of queries in elasticsearch
<p>I am trying to issue a query to elasticsearch which does filter by, group by, sum aggregation and ordering. I have got 2 questions: how a query should look like and what are the performance implications for elasticsearch?</p>&#xA;&#xA;<p>Let me give an example data set to support my question. Let's say I have got a set of sales:</p>&#xA;&#xA;<pre><code>document type: 'sales' with the following fields and data:&#xA;sale_datetime    | sold_product  | sold_at_price&#xA;-----------------|---------------|--------------&#xA;2015-11-24 12:00 | some product  | 100&#xA;2015-11-24 12:30 | some product  | 100&#xA;2015-11-24 12:30 | other product | 100&#xA;2015-11-24 13:00 | other product | 100&#xA;2015-11-24 12:30 | some product  | 200&#xA;2015-11-24 13:00 | some product  | 200&#xA;</code></pre>&#xA;&#xA;<p>I would like to issue a query which:</p>&#xA;&#xA;<ul>&#xA;<li>takes into account only sales in the time interval from 2015-11-24 12:15 to 2015-11-24 12:45</li>&#xA;<li>groups the result by sold_product field</li>&#xA;<li>calculates the 'sum over sold_at_price values per product'</li>&#xA;<li>returns rows in the order that the biggest 'sum over sold_at_price values per product' comes first, next is the second and so on.</li>&#xA;</ul>&#xA;&#xA;<p>Applying it to the sample data set above, it would return the following result:</p>&#xA;&#xA;<pre><code>sold_product  | sum of sold_at_price&#xA;--------------|--------------&#xA;some product  | 300     // takes into account rows 2 and 5&#xA;other product | 100     // takes into account row 3&#xA;</code></pre>&#xA;&#xA;<p>If it is possible to issue such a query, what are the important performance implications for elasticsearch? If it matters for consideration:</p>&#xA;&#xA;<ul>&#xA;<li>there are many (hundreds of thousands, potentially millions in the future) of unique products </li>&#xA;<li>product name may include multiple (few tens) words/terms (It is possible to generate a unique product name consisting 1 word only, but it would almost double the volume of data)</li>&#xA;<li>usually there are many (millions) records satisfying the time range filter (in some cases the filter can be narrowed down to few tens of thousands records in a time range, but it can not be guaranteed)</li>&#xA;</ul>&#xA;&#xA;<p>Thanks in advance for your help! </p>&#xA;
<p>This is a typical use case for <a href="https://www.elastic.co/guide/en/elasticsearch/reference/1.7/search-aggregations.html" rel="nofollow">aggregations</a>. Let's start by creating an index and modeling the mapping of your data. We have a normal <a href="https://www.elastic.co/guide/en/elasticsearch/reference/1.7/mapping-core-types.html#date" rel="nofollow"><code>date</code> field for <code>sold_datetime</code></a>, another <a href="https://www.elastic.co/guide/en/elasticsearch/reference/1.7/mapping-core-types.html#number" rel="nofollow">numeric field for <code>sold_at_price</code></a> and a <a href="https://www.elastic.co/guide/en/elasticsearch/reference/1.7/mapping-core-types.html#_multi_fields_3" rel="nofollow">multi-field of type string for <code>sold_product</code></a>. You'll notice that this multi-field has a sub-field called <code>raw</code> that is <code>not_analyzed</code> and will be used to create the aggregation on the product name:</p>&#xA;&#xA;<pre><code>curl -XPUT localhost:9200/sales -d '{&#xA;  "mappings": {&#xA;    "sale": {&#xA;      "properties": {&#xA;        "sale_datetime": {&#xA;          "type": "date"&#xA;        },&#xA;        "sold_product": {&#xA;          "type": "string",&#xA;          "fields": {&#xA;            "raw": {&#xA;              "type": "string",&#xA;              "index": "not_analyzed"&#xA;            }&#xA;          }&#xA;        },&#xA;        "sold_at_price": {&#xA;          "type": "double"&#xA;        }&#xA;      }&#xA;    }&#xA;  }&#xA;}'&#xA;</code></pre>&#xA;&#xA;<p>Now let's index your sample data set using the <code>_bulk</code> endpoint of your new index:</p>&#xA;&#xA;<pre><code>curl -XPOST localhost:9200/sales/sale/_bulk -d '&#xA;{"index": {}}&#xA;{"sold_datetime": "2015-11-24T12:00:00.000Z", "sold_product":"some product", "sold_at_price": 100}&#xA;{"index": {}}&#xA;{"sold_datetime": "2015-11-24T12:30:00.000Z", "sold_product":"some product", "sold_at_price": 100}&#xA;{"index": {}}&#xA;{"sold_datetime": "2015-11-24T12:30:00.000Z", "sold_product":"other product", "sold_at_price": 100}&#xA;{"index": {}}&#xA;{"sold_datetime": "2015-11-24T13:00:00.000Z", "sold_product":"other product", "sold_at_price": 100}&#xA;{"index": {}}&#xA;{"sold_datetime": "2015-11-24T12:30:00.000Z", "sold_product":"some product", "sold_at_price": 200}&#xA;{"index": {}}&#xA;{"sold_datetime": "2015-11-24T13:00:00.000Z", "sold_product":"some product", "sold_at_price": 200}&#xA;'&#xA;</code></pre>&#xA;&#xA;<p>Finally, let's create the query and aggregation that you need:</p>&#xA;&#xA;<pre><code>curl -XPOST localhost:9200/sales/sale/_search -d '{&#xA;  "size": 0,&#xA;  "query": {&#xA;    "filtered": {&#xA;      "filter": {&#xA;        "range": {&#xA;          "sold_datetime": {&#xA;            "gt": "2015-11-24T12:15:00.000Z",&#xA;            "lt": "2015-11-24T12:45:00.000Z"&#xA;          }&#xA;        }&#xA;      }&#xA;    }&#xA;  },&#xA;  "aggs": {&#xA;    "sold_products": {&#xA;      "terms": {&#xA;        "field": "sold_product.raw",&#xA;        "order": {&#xA;          "total": "desc"&#xA;        }&#xA;      },&#xA;      "aggs": {&#xA;        "total": {&#xA;          "sum": {&#xA;            "field": "sold_at_price"&#xA;          }&#xA;        }&#xA;      }&#xA;    }&#xA;  }&#xA;}'&#xA;</code></pre>&#xA;&#xA;<p>As you can see we're filtering on a specific date interval for the <code>sold_datetime</code> field (12:15-12:45 on Nov 24th). The aggregation part defines a <a href="https://www.elastic.co/guide/en/elasticsearch/reference/1.7/search-aggregations-bucket-terms-aggregation.html" rel="nofollow"><code>terms</code> aggregation</a> on the <code>sold_product.raw</code> field and for each bucket we <a href="https://www.elastic.co/guide/en/elasticsearch/reference/1.7/search-aggregations-metrics-sum-aggregation.html" rel="nofollow"><code>sum</code></a> the values of the <code>sold_at_price</code> field.</p>&#xA;&#xA;<p>Note that in order to make it performant if you have several million documents that could potentially match, you need to apply the most aggressive filters first, maybe the id of the business for which you're running the query, or some other criteria that will exclude as many documents as possible before running the aggregation.</p>&#xA;&#xA;<p>The result looks like this:</p>&#xA;&#xA;<pre><code>{&#xA;  ...&#xA;  "aggregations" : {&#xA;    "sold_products" : {&#xA;      "doc_count_error_upper_bound" : 0,&#xA;      "sum_other_doc_count" : 0,&#xA;      "buckets" : [ {&#xA;        "key" : "some product",&#xA;        "doc_count" : 2,&#xA;        "total" : {&#xA;          "value" : 300.0&#xA;        }&#xA;      }, {&#xA;        "key" : "other product",&#xA;        "doc_count" : 1,&#xA;        "total" : {&#xA;          "value" : 100.0&#xA;        }&#xA;      } ]&#xA;    }&#xA;  }&#xA;}&#xA;</code></pre>&#xA;