31279916
Mapping fields with special character # fails
<p>I mapped a field in elastic search so that it gets analyzed with an edge 2gram tokenizer:</p>&#xA;&#xA;<pre><code>"google.title.#t": {&#xA;  "type": "string",&#xA;   "index_analyzer": "edge_2gram_body_analyzer",&#xA;   "search_analyzer": "standard"&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>When I get the mapping, it seems healthy. I would expect this:</p>&#xA;&#xA;<pre><code>POST myIndex/_analyze?field=google.title.#t&#xA;{"test"}&#xA;</code></pre>&#xA;&#xA;<p>to return the tokens:</p>&#xA;&#xA;<pre><code>te, tes, test&#xA;</code></pre>&#xA;&#xA;<p>Yet, it does not, it returns "test" instead: it is defaulting to the standard analyzer.</p>&#xA;&#xA;<p>Now, when I remove the # from the key (google.title.t), it works. Is there a way I can escape the # at mapping time? What are the other forbidden characters?</p>&#xA;
<p>This is becuase "<strong><em>#</em></strong>" in url needs to be <a href="http://www.w3schools.com/tags/ref_urlencode.asp" rel="nofollow">url-encoded</a><br>&#xA;Example:</p>&#xA;&#xA;<pre><code>POST myIndex/_analyze?field=google.title.%23t&amp;text=text&#xA;</code></pre>&#xA;