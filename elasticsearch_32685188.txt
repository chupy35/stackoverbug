32685188
Elasticsearch shard relocation not working
<p>I added 12 new data nodes to an existing cluster of 8 data nodes.  I am trying to shutdown the previous 8 nodes using the "exclude allocation" as recommended</p>&#xA;&#xA;<blockquote>&#xA;  <p>curl -XPUT localhost:9200/_cluster/settings -d '{&#xA;      "transient" : {&#xA;          "cluster.routing.allocation.exclude._ip" : "10.0.0.1"&#xA;      } }'</p>&#xA;</blockquote>&#xA;&#xA;<p>It wasn't relocating any shards, so I ran the reroute command with the 'explain' option.  Can someone explain what the following text is saying ?</p>&#xA;&#xA;<pre><code>&gt;  "explanations" : [ {&#xA;&gt;     "command" : "move",&#xA;&gt;     "parameters" : {&#xA;&gt;       "index" : "2015-09-20",&#xA;&gt;       "shard" : 0,&#xA;&gt;       "from_node" : "_dDn1SmqSquhMGgjti6vGg",&#xA;&gt;       "to_node" : "OQBFMt17RaWboOzMnUy2jA"&#xA;&gt;     },&#xA;&gt;     "decisions" : [ {&#xA;&gt;       "decider" : "same_shard",&#xA;&gt;       "decision" : "YES",&#xA;&gt;       "explanation" : "shard is not allocated to same node or host"&#xA;&gt;     }, {&#xA;&gt;       "decider" : "filter",&#xA;&gt;       "decision" : "YES",&#xA;&gt;       "explanation" : "node passes include/exclude/require filters"&#xA;&gt;     }, {&#xA;&gt;       "decider" : "replica_after_primary_active",&#xA;&gt;       "decision" : "YES",&#xA;&gt;       "explanation" : "shard is primary"&#xA;&gt;     }, {&#xA;&gt;       "decider" : "throttling",&#xA;&gt;       "decision" : "YES",&#xA;&gt;       "explanation" : "below shard recovery limit of [16]"&#xA;&gt;     }, {&#xA;&gt;       "decider" : "enable",&#xA;&gt;       "decision" : "YES",&#xA;&gt;       "explanation" : "allocation disabling is ignored"&#xA;&gt;     }, {&#xA;&gt;       "decider" : "disable",&#xA;&gt;       "decision" : "YES",&#xA;&gt;       "explanation" : "allocation disabling is ignored"&#xA;&gt;     }, {&#xA;&gt;       "decider" : "awareness",&#xA;&gt;       "decision" : "NO",&#xA;&gt;       "explanation" : "too many shards on nodes for attribute: [dc]"  }, {&#xA;&gt;       "decider" : "shards_limit",&#xA;&gt;       "decision" : "YES",&#xA;&gt;       "explanation" : "total shard limit disabled: [-1] &lt;= 0"&#xA;&gt;     }, {&#xA;&gt;       "decider" : "node_version",&#xA;&gt;       "decision" : "YES",&#xA;&gt;       "explanation" : "target node version [1.4.5] is same or newer than source node version [1.4.5]"&#xA;&gt;     }, {&#xA;&gt;       "decider" : "disk_threshold",&#xA;&gt;       "decision" : "YES",&#xA;&gt;       "explanation" : "enough disk for shard on node, free: [1.4tb]"&#xA;&gt;     }, {&#xA;&gt;       "decider" : "snapshot_in_progress",&#xA;&gt;       "decision" : "YES", "explanation" : "no snapshots are currently running"&#xA;&gt;     &#xA;</code></pre>&#xA;
<p>You can install kopf plugin, it will help you manage elasticsearch nodes and the task will be more simplified.</p>&#xA;&#xA;<p>With this plugin what you want it's easier.</p>&#xA;&#xA;<p>You can download here: <a href="https://github.com/lmenezes/elasticsearch-kopf" rel="nofollow">https://github.com/lmenezes/elasticsearch-kopf</a> .</p>&#xA;&#xA;<p>Other plugins with support you can get in: <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-plugins.html" rel="nofollow">https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-plugins.html</a> .</p>&#xA;
<p>If you have replicas, you can simply switch off your nodes, one by one and wait for each that the cluster becomes green again.</p>&#xA;&#xA;<p>You don't need to explicitly reroute in that case.</p>&#xA;&#xA;<p>That said, in your logs, it sounds like you are using <code>awareness</code> in your <code>elasticsearch.yml</code> file. You should check your settings.</p>&#xA;