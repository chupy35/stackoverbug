34404771
analyzed vs not_analyzed: storage size
<p>I recently started using ElasticSearch 2. And as I undestand <strong>analyzed</strong> vs <strong>not_analyzed</strong> in the mapping, not_analyzed should be better in storage (<a href="https://www.elastic.co/blog/elasticsearch-storage-the-true-story-2.0" rel="nofollow">https://www.elastic.co/blog/elasticsearch-storage-the-true-story-2.0</a> and <a href="https://www.elastic.co/blog/elasticsearch-storage-the-true-story" rel="nofollow">https://www.elastic.co/blog/elasticsearch-storage-the-true-story</a>). &#xA;For testing purposes I created some indexes with all the String field as analyzed (by default) and then I created some other indexes with all the fields as not_analyzed, my surprise came when I checked the size of the indexes and I saw that the indexes with the not_analyzed Strings were 40% <strong>bigger</strong>!! I was inserting the same documents in each index (35000 docs). </p>&#xA;&#xA;<p>Any idea why this is happening? My documents are simple JSON documents. I have 60 String fields in each document that I want to set as not_analyzed and I tried both setting each field as not analyzed and also creating a dynamic template. </p>&#xA;&#xA;<p>I edit for adding the mapping, although I think it has nothing special:</p>&#xA;&#xA;<pre><code>    {&#xA;        "mappings": {&#xA;            "my_type" : {&#xA;                          "_ttl" : { "enabled" : true, "default" : "7d" },&#xA;                          "properties" : {&#xA;                                "field1" : {&#xA;                                    "properties" : {&#xA;                                        "field2" : {&#xA;                                            "type" : "string", "index" : "not_analyzed"&#xA;                                        }&#xA;                                        more not_analyzed String fields here&#xA;                                  ...&#xA;                              ...&#xA;                          ...&#xA;}&#xA;</code></pre>&#xA;
<p>From <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/string.html" rel="nofollow">the documentation</a>, it looks like <code>not_analyzed</code> makes the field act like a "keyword" instead of a "full-text" field -- let's compare these two!</p>&#xA;&#xA;<h1>Full text</h1>&#xA;&#xA;<blockquote>&#xA;  <p>These fields are analyzed, that is they are passed through an analyzer to convert the string into a list of individual terms before being indexed.</p>&#xA;</blockquote>&#xA;&#xA;<h1>Keyword</h1>&#xA;&#xA;<blockquote>&#xA;  <p>Keyword fields are not_analyzed. Instead, the exact string value is added to the index as a single term.</p>&#xA;</blockquote>&#xA;&#xA;<p>I'm not surprised that storing an entire string as a term, rather than breaking it into a list of terms, doesn't necessarily translate to saved space. Honestly, it probably depends on the index's analyzer and the string being indexed.</p>&#xA;&#xA;<hr>&#xA;&#xA;<p>As a side note, I just re-indexed about a million documents of production data and cut our index disk space usage by ~95%. The main difference I made was modifying what was actually saved in the source (AKA stored). We indexed PDFs for searching, but did not need them to be returned and so that saved us from saving this information in two different ways (analyzed and raw). There are some <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-source-field.html" rel="nofollow">very real downsides</a> to this, though, so be careful!</p>&#xA;
<p><code>not_analyzed</code> fields are still <em>indexed</em>.  They just don't have any transformations applied to them beforehand ("analysis" - in Lucene parlance).</p>&#xA;&#xA;<p><strong>As an example:</strong></p>&#xA;&#xA;<blockquote>&#xA;  <p>(Doc 1) "The quick brown fox jumped over the lazy dog"</p>&#xA;  &#xA;  <p>(Doc 2) "Lazy like the fox"</p>&#xA;</blockquote>&#xA;&#xA;<hr>&#xA;&#xA;<blockquote>&#xA;  <ol>&#xA;  <li>Simplified postings list created by <em>Standard Analyzer</em> (default for <code>analyzed</code> string fields - tokenized, lowercased, stopwords removed): </li>&#xA;  </ol>&#xA;</blockquote>&#xA;&#xA;<pre><code>"brown": [1]  &#xA;"dog": [1]  &#xA;"fox": [1,2]  &#xA;"jumped": [1]  &#xA;"lazy": [1,2]  &#xA;"over": [1] &#xA;"quick": [1]&#xA;</code></pre>&#xA;&#xA;<p><em>30 characters worth of string data</em></p>&#xA;&#xA;<hr>&#xA;&#xA;<blockquote>&#xA;  <ol start="2">&#xA;  <li>Simplified postings list created by <code>"index": "not_analyzed"</code>: </li>&#xA;  </ol>&#xA;</blockquote>&#xA;&#xA;<pre><code>"The quick brown fox jumped over the lazy dog": [1]  &#xA;"Lazy like the fox": [2] &#xA;</code></pre>&#xA;&#xA;<p><em>62 characters worth of string data</em></p>&#xA;&#xA;<hr>&#xA;&#xA;<p>Analysis causes input to get tokenized and normalized for the purpose of being able to look up documents using a term.  </p>&#xA;&#xA;<p>But as a result, the unit of text is reduced to a normalized term <em>(vs an entire field with <code>not_analyzed</code>)</em>, and all the redundant (normalized) terms <em>across all documents</em> are collapsed into a <strong>single logical list</strong> saving you all the space that would normally be consumed by repeated terms and stopwords.</p>&#xA;